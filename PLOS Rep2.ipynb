{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1mSoX9nFUSqu"
   },
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "from pennylane.templates import RandomLayers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"\" # Data saving folder\n",
    "PREPROCESS = True           # If False, skip quantum processing and load data from SAVE_PATH\n",
    "np.random.seed(0)           # Seed for NumPy random number generator\n",
    "tf.random.set_seed(0)  \n",
    "#dataset_root = \"D:/PhD_FUUAST/mail farina/quanvolution_PC/Dataset_1\"\n",
    "dataset_root = \"\"\n",
    "n_layers = 1   # Number of random layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xbfe26HZyphf"
   },
   "outputs": [],
   "source": [
    "def load_custom_dataset(root_folder, image_size=(100, 100)):\n",
    "  class_names = sorted(os.listdir(dataset_root))\n",
    "  class_map = {class_name: idx for idx, class_name in enumerate(class_names)}\n",
    "  class_map\n",
    "  print(class_names)\n",
    "  for class_name in class_names:\n",
    "        class_folder = os.path.join(dataset_root, class_name)\n",
    "        if os.path.isdir(class_folder):\n",
    "            for image_name in os.listdir(class_folder):\n",
    "                image_path = os.path.join(class_folder, image_name)\n",
    "                try:\n",
    "                    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "                    image = cv2.resize(image, image_size)\n",
    "                    images.append(image)\n",
    "                    labels.append(class_map[class_name])\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading image: {image_path}, Error: {e}\")\n",
    "\n",
    "  return np.array(images), np.array(labels)\n",
    "\n",
    "\n",
    "images = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_root = \"/content/gdrive/MyDrive/Dataset_1\"\n",
    "images, labels = load_custom_dataset(dataset_root)\n",
    "print(f\"Loaded {len(images)} images and {len(set(labels))} classes.\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
    "print(f\"Training samples: {X_train.shape[0]}, Testing samples: {X_test.shape[0]}\")\n",
    "n_train = X_train.shape[0]    # Size of the train dataset\n",
    "n_test = X_test.shape[0]     # Size of the test dataset\n",
    "train_images=X_train\n",
    "test_images  =X_test\n",
    "train_images = train_images / 255\n",
    "test_images = test_images / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.array(train_images[..., np.newaxis])\n",
    "test_images = np.array(test_images[..., np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run this\n",
    "import numpy as np\n",
    "import pennylane as qml\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Define the quantum device with 12 qubits\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "# Number of layers in the random circuit\n",
    "rand_params = np.random.uniform(high=2 * np.pi, size=(n_layers, 4,3))\n",
    "# Random circuit parameters for each color channel\n",
    "rand_params_red = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "#rand_params_green = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "#rand_params_blue = np.random.uniform(high=2 * np.pi, size=(n_layers, 4))\n",
    "\n",
    "entangler = qml.CZ\n",
    "# Quantum circuit function\n",
    "@qml.qnode(dev)\n",
    "def circuit(phi):\n",
    "    \"\"\"Quantum circuit for processing RGB image channels.\"\"\"\n",
    "\n",
    "    # Red channel (Q0-Q3)\n",
    "    for j in range(4):\n",
    "        qml.RY(np.pi * phi[j], wires=j)\n",
    "        qml.Hadamard(wires=j)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "    qml.StronglyEntanglingLayers(rand_params[:, :4], wires=[0, 1, 2, 3],imprimitive=entangler)\n",
    "    #qml.StronglyEntanglingLayers(rand_params[:, 4:8], wires=[4, 5, 6, 7],imprimitive=entangler)\n",
    "    #qml.StronglyEntanglingLayers(rand_params[:, 8:], wires=[8, 9, 10, 11],imprimitive=entangler)\n",
    "\n",
    "   \n",
    "\n",
    "    # Measurement\n",
    "    return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n",
    "\n",
    "def quanv(image):\n",
    "    \"\"\"Convolves the input RGB image with the quantum circuit.\"\"\"\n",
    "    out = np.zeros((image.shape[0] // 2, image.shape[1] // 2, 4))\n",
    "\n",
    "    # Process each channel (RGB) separately\n",
    "    for channel in range(1):\n",
    "        # Loop over the coordinates of the top-left pixel of 2x2 squares\n",
    "        for j in range(0, image.shape[0], 2):\n",
    "            for k in range(0, image.shape[1], 2):\n",
    "                # Process a squared 2x2 region of the image with the quantum circuit\n",
    "                q_results = circuit(\n",
    "                    [\n",
    "                        image[j, k, 0] ,\n",
    "                        image[j, k + 1, 0] ,\n",
    "                        image[j + 1, k, 0] ,\n",
    "                        image[j + 1, k + 1, 0] \n",
    "                    ]\n",
    "                )\n",
    "                # Assign expectation values to the output pixel (j/2, k/2, channel)\n",
    "                for c in range(4):\n",
    "                    out[j // 2, k // 2, c] = q_results[c]\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def plot_circuit():\n",
    "    \"\"\"Plots the quantum circuit using PennyLane's draw_mpl function.\"\"\"\n",
    "    # Create circuit visualization figure\n",
    "    circuit_fig = qml.draw_mpl(circuit, expansion_strategy=\"device\")([0,0,0,0])\n",
    "\n",
    "    # Display the circuit diagram\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Plot the quantum circuit\n",
    "plot_circuit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pennylane as qml\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of layers\n",
    "n_layers = 5\n",
    "\n",
    "# Define the entanglers\n",
    "entanglers = [qml.CZ, qml.CNOT]  # List of entangling gates\n",
    "\n",
    "# Device setup\n",
    "dev = qml.device(\"default.qubit\", wires=4)\n",
    "\n",
    "def create_circuit(layer_num, entangler):\n",
    "    \"\"\"Creates a quantum circuit with specified layers and entangler.\"\"\"\n",
    "    # Random circuit parameters\n",
    "    rand_params = np.random.uniform(high=2 * np.pi, size=(layer_num, 4, 3))\n",
    "\n",
    "    @qml.qnode(dev)\n",
    "    def circuit(phi):\n",
    "        for j in range(4):\n",
    "            qml.RY(np.pi * phi[j], wires=j)\n",
    "            qml.Hadamard(wires=j)\n",
    "        qml.StronglyEntanglingLayers(rand_params, wires=list(range(4)), imprimitive=entangler)\n",
    "        return [qml.expval(qml.PauliZ(j)) for j in range(4)]\n",
    "    \n",
    "    return circuit\n",
    "\n",
    "def plot_and_save_circuit(layer_num, entangler, save_path):\n",
    "    \"\"\"Plots and saves the quantum circuit.\"\"\"\n",
    "    circuit = create_circuit(layer_num, entangler)\n",
    "    \n",
    "    # Plot the quantum circuit\n",
    "    circuit_fig = qml.draw_mpl(circuit, expansion_strategy=\"device\")([0, 0, 0, 0])\n",
    "    \n",
    "    # Save the figure to a file\n",
    "    plt.axis('off')\n",
    "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "# Plot and save circuits for each layer and entangler type\n",
    "save_directory = \"D:/PhD_FUUAST/paper2/layers circuit/\"\n",
    "for layer_num in range(1, n_layers + 1):\n",
    "    for entangler in entanglers:\n",
    "        entangler_name = \"CZ\" if entangler == qml.CZ else \"CNOT\"\n",
    "        save_path = f\"{save_directory}Layer_{layer_num}_{entangler_name}.png\"\n",
    "        plot_and_save_circuit(layer_num, entangler, save_path)\n",
    "        print(f\"Saved Layer {layer_num} with {entangler_name} to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6PuAFolcTKo6"
   },
   "outputs": [],
   "source": [
    "if PREPROCESS == True:\n",
    "    q_train_images = []\n",
    "    print(\"Quantum pre-processing of train images:\")\n",
    "    for idx, img in enumerate(train_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_train), end=\"\\r\")\n",
    "        q_train_images.append(quanv(img))\n",
    "    q_train_images = np.asarray(q_train_images)\n",
    "\n",
    "    q_test_images = []\n",
    "    print(\"\\nQuantum pre-processing of test images:\")\n",
    "    for idx, img in enumerate(test_images):\n",
    "        print(\"{}/{}        \".format(idx + 1, n_test), end=\"\\r\")\n",
    "        q_test_images.append(quanv(img))\n",
    "    q_test_images = np.asarray(q_test_images)\n",
    "\n",
    "    # Save pre-processed images\n",
    "    np.save(SAVE_PATH + \"2x2_q_train_images\", q_train_images)\n",
    "    np.save(SAVE_PATH + \"2x2_q_test_image\", q_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(SAVE_PATH + \"2x2_q_train_images_0.npy\", q_train_images)\n",
    "np.save(SAVE_PATH + \"2x2_q_test_images_0.npy\", q_test_images)\n",
    "\n",
    "print(q_test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 4\n",
    "n_channels = 4\n",
    "fig, axes = plt.subplots(1 + n_channels, n_samples, figsize=(20,20))\n",
    "for k in range(n_samples):\n",
    "    axes[0, 0].set_ylabel(\"Input\")\n",
    "    if k != 0:\n",
    "        axes[0, k].yaxis.set_visible(False)\n",
    "    axes[0, k].imshow(train_images[k, :, :, 0], cmap=\"gray\")\n",
    "\n",
    "    # Plot all output channels\n",
    "    for c in range(n_channels):\n",
    "        axes[c + 1, 0].set_ylabel(\"Output [ch. {}]\".format(c))\n",
    "        if k != 0:\n",
    "            axes[c, k].yaxis.set_visible(False)\n",
    "        axes[c + 1, k].imshow(q_train_images[k, :, :, c], cmap=\"gray\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# For CNOT gate\n",
    "train_images_L1_CNOT = np.load(SAVE_PATH + \"2x2_q_train_images_0.npy\")\n",
    "test_images_L1_CNOT = np.load(SAVE_PATH + \"2x2_q_test_images_0.npy\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Number of samples and channels to display\n",
    "n_samples = 1  # Only 1 sample for comparison\n",
    "n_channels = 4  # Assuming 4 channels\n",
    "\n",
    "# List of datasets for all layers (L1 to L5 for CNOT and CZ)\n",
    "datasets = [\n",
    "    (train_images_L1_CNOT, \"L1 CNOT\")\n",
    "]\n",
    "\n",
    "# Create a figure for comparison across all layers and operations\n",
    "fig, axes = plt.subplots(len(datasets), n_channels + 1, figsize=(15, 40))\n",
    "fig.suptitle(\"Comparison of Layers Across CNOT and CZ\", fontsize=16)\n",
    "\n",
    "# Iterate over datasets and plot\n",
    "for i, (images, label) in enumerate(datasets):\n",
    "    # Input image\n",
    "    axes[i, 0].set_title(f\"{label} Input\", fontsize=14)\n",
    "    axes[i, 0].imshow(images[0, :, :, 0], cmap=\"gray\")\n",
    "    axes[i, 0].axis('off')  # Hide axes ticks and labels\n",
    "\n",
    "    # Output channels\n",
    "    for c in range(n_channels):\n",
    "        ax = axes[i, c + 1]\n",
    "        ax.set_title(f\"Output [ch. {c}]\", fontsize=12)\n",
    "        ax.imshow(images[0, :, :, c], cmap=\"gray\")\n",
    "        ax.axis('off')  # Hide axes ticks and labels\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.95)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"Creates and returns a CNN model with backpropagation.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, categories, title):\n",
    "    \"\"\"Plots confusion matrix.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=categories, yticklabels=categories)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "def compute_and_plot_confusion_matrix(model, test_images, test_labels, categories, model_name):\n",
    "    \"\"\"Computes and plots the confusion matrix.\"\"\"\n",
    "    # Generate predictions\n",
    "    y_scores = model.predict(test_images)\n",
    "    predicted_labels = np.argmax(y_scores, axis=1)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(test_labels, predicted_labels, labels=np.arange(len(categories)))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(cm, categories, f'Confusion Matrix for {model_name}')\n",
    "\n",
    "def plot_training_validation_accuracy(histories):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training accuracy\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['accuracy'], label=f'{key} Train Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['val_accuracy'], label=f'{key} Validation Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(histories):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['loss'], label=f'{key} Train Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation loss\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['val_loss'], label=f'{key} Validation Loss')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions(images, true_labels, predictions, title):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f\"True: {true_labels[i]}\\nPred: {predictions[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    'L1_CNOT': {\n",
    "        'train': np.load(SAVE_PATH + \"2x2_q_train_images_0.npy\"),\n",
    "        'test': np.load(SAVE_PATH + \"2x2_q_test_images_0.npy\"),\n",
    "    'L1_CZ': {\n",
    "        'train': np.load(SAVE_PATH + \"2x2_q_train_images_0.npy\"),\n",
    "        'test': np.load(SAVE_PATH + \"2x2_q_test_images_0.npy\"),\n",
    "    }\n",
    "  \n",
    "}\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 32\n",
    "n_epochs = 40\n",
    "\n",
    "# Define labels\n",
    "train_labels = y_train\n",
    "test_labels = y_test\n",
    "\n",
    "# Create and train CNN models for different datasets\n",
    "histories = {}\n",
    "predictions = {}\n",
    "test_accuracies = {}\n",
    "for key, data in datasets.items():\n",
    "    print(f\"Model: {key}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_cnn_model(input_shape=(50, 50, 4), num_classes=3)\n",
    "    \n",
    "    # Print model summary\n",
    "    print(f\"\\nSummary for {key} Model:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train the model\n",
    "    histories[key] = model.fit(\n",
    "        data['train'], train_labels,  # Assuming train_labels is the correct label for all\n",
    "        validation_data=(data['test'], test_labels),\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(data['test'], test_labels, verbose=0)\n",
    "    test_accuracies[key] = test_acc * 100  # Convert to percentage\n",
    "    # Compute and plot confusion matrix\n",
    "    compute_and_plot_confusion_matrix(model, test_images, test_labels, categories, key)\n",
    "    # Generate predictions on the test set\n",
    "    test_preds = model.predict(data['test'])\n",
    "    predictions[key] = np.argmax(test_preds, axis=1)\n",
    "# Plot training and validation accuracy separately\n",
    "plot_training_validation_accuracy(histories)\n",
    "\n",
    "\n",
    "# Plot loss separately\n",
    "plot_loss(histories)\n",
    "\n",
    "# Print test accuracy for each model\n",
    "for key, accuracy in test_accuracies.items():\n",
    "    print(f\"Model: {key} - Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_train_images[1, :, :, 1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qg-Uc0Aw4kGx"
   },
   "outputs": [],
   "source": [
    "def MyModel():\n",
    "    \"\"\"Initializes and returns a custom Keras model\n",
    "    which is ready to be trained.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RGMSDYEwd_yL",
    "outputId": "f83d3a94-6cd3-42e2-c557-ad4ab0aa3535"
   },
   "outputs": [],
   "source": [
    "train_labels = y_train\n",
    "test_labels = y_test\n",
    "q_model_L1 = MyModel()\n",
    "\n",
    "\n",
    "# Train models\n",
    "q_history_L1 = q_model_L1.fit(\n",
    "    q_train_images,\n",
    "    train_labels,\n",
    "    validation_data=(q_test_images, test_labels),\n",
    "    batch_size=128,\n",
    "    epochs=300,\n",
    "    verbose=2,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUVv81kgejRf",
    "outputId": "47c60566-861e-4311-f932-72d91e36f448"
   },
   "outputs": [],
   "source": [
    "c_model = MyModel()\n",
    "\n",
    "c_history = c_model.fit(\n",
    "    train_images,\n",
    "    y_train,\n",
    "    validation_data=(test_images, y_test),\n",
    "    batch_size=128,\n",
    "    epochs=300,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/300\n",
      "469/469 - 1s - loss: 0.0342 - accuracy: 0.9935 - val_loss: 0.2376 - val_accuracy: 0.9378\n",
      "Epoch 125/300\n",
      "469/469 - 1s - loss: 0.0342 - accuracy: 0.9937 - val_loss: 0.2382 - val_accuracy: 0.9380\n",
      "Epoch 126/300\n",
      "469/469 - 1s - loss: 0.0341 - accuracy: 0.9936 - val_loss: 0.2382 - val_accuracy: 0.9376\n",
      "Epoch 127/300\n",
      "469/469 - 1s - loss: 0.0341 - accuracy: 0.9934 - val_loss: 0.2379 - val_accuracy: 0.9374\n",
      "Epoch 128/300\n",
      "469/469 - 1s - loss: 0.0340 - accuracy: 0.9937 - val_loss: 0.2393 - val_accuracy: 0.9368\n",
      "Epoch 129/300\n",
      "469/469 - 1s - loss: 0.0339 - accuracy: 0.9936 - val_loss: 0.2384 - val_accuracy: 0.9375\n",
      "Epoch 130/300\n",
      "469/469 - 1s - loss: 0.0339 - accuracy: 0.9937 - val_loss: 0.2390 - val_accuracy: 0.9370\n",
      "Epoch 131/300\n",
      "469/469 - 1s - loss: 0.0338 - accuracy: 0.9936 - val_loss: 0.2404 - val_accuracy: 0.9370\n",
      "Epoch 132/300\n",
      "469/469 - 1s - loss: 0.0338 - accuracy: 0.9938 - val_loss: 0.2393 - val_accuracy: 0.9374\n",
      "Epoch 133/300\n",
      "469/469 - 1s - loss: 0.0337 - accuracy: 0.9936 - val_loss: 0.2395 - val_accuracy: 0.9378\n",
      "Epoch 134/300\n",
      "469/469 - 1s - loss: 0.0337 - accuracy: 0.9939 - val_loss: 0.2407 - val_accuracy: 0.9371\n",
      "Epoch 135/300\n",
      "469/469 - 1s - loss: 0.0336 - accuracy: 0.9937 - val_loss: 0.2396 - val_accuracy: 0.9373\n",
      "Epoch 136/300\n",
      "469/469 - 1s - loss: 0.0336 - accuracy: 0.9940 - val_loss: 0.2406 - val_accuracy: 0.9371\n",
      "Epoch 137/300\n",
      "469/469 - 1s - loss: 0.0335 - accuracy: 0.9940 - val_loss: 0.2401 - val_accuracy: 0.9375\n",
      "Epoch 138/300\n",
      "469/469 - 1s - loss: 0.0335 - accuracy: 0.9938 - val_loss: 0.2399 - val_accuracy: 0.9376\n",
      "Epoch 139/300\n",
      "469/469 - 1s - loss: 0.0334 - accuracy: 0.9936 - val_loss: 0.2405 - val_accuracy: 0.9371\n",
      "Epoch 140/300\n",
      "469/469 - 1s - loss: 0.0333 - accuracy: 0.9938 - val_loss: 0.2403 - val_accuracy: 0.9378\n",
      "Epoch 141/300\n",
      "469/469 - 1s - loss: 0.0332 - accuracy: 0.9941 - val_loss: 0.2415 - val_accuracy: 0.9372\n",
      "Epoch 142/300\n",
      "469/469 - 1s - loss: 0.0332 - accuracy: 0.9941 - val_loss: 0.2408 - val_accuracy: 0.9373\n",
      "Epoch 143/300\n",
      "469/469 - 1s - loss: 0.0332 - accuracy: 0.9937 - val_loss: 0.2409 - val_accuracy: 0.9375\n",
      "Epoch 144/300\n",
      "469/469 - 1s - loss: 0.0331 - accuracy: 0.9939 - val_loss: 0.2413 - val_accuracy: 0.9376\n",
      "Epoch 145/300\n",
      "469/469 - 1s - loss: 0.0331 - accuracy: 0.9940 - val_loss: 0.2419 - val_accuracy: 0.9373\n",
      "Epoch 146/300\n",
      "469/469 - 1s - loss: 0.0330 - accuracy: 0.9938 - val_loss: 0.2413 - val_accuracy: 0.9373\n",
      "Epoch 147/300\n",
      "469/469 - 1s - loss: 0.0330 - accuracy: 0.9940 - val_loss: 0.2417 - val_accuracy: 0.9376\n",
      "Epoch 148/300\n",
      "469/469 - 1s - loss: 0.0329 - accuracy: 0.9940 - val_loss: 0.2423 - val_accuracy: 0.9372\n",
      "Epoch 149/300\n",
      "469/469 - 1s - loss: 0.0329 - accuracy: 0.9941 - val_loss: 0.2427 - val_accuracy: 0.9374\n",
      "Epoch 150/300\n",
      "469/469 - 1s - loss: 0.0328 - accuracy: 0.9940 - val_loss: 0.2428 - val_accuracy: 0.9367\n",
      "Epoch 151/300\n",
      "469/469 - 1s - loss: 0.0328 - accuracy: 0.9941 - val_loss: 0.2431 - val_accuracy: 0.9370\n",
      "Epoch 152/300\n",
      "469/469 - 1s - loss: 0.0327 - accuracy: 0.9940 - val_loss: 0.2432 - val_accuracy: 0.9369\n",
      "Epoch 153/300\n",
      "469/469 - 1s - loss: 0.0327 - accuracy: 0.9940 - val_loss: 0.2430 - val_accuracy: 0.9370\n",
      "Epoch 154/300\n",
      "469/469 - 1s - loss: 0.0326 - accuracy: 0.9941 - val_loss: 0.2424 - val_accuracy: 0.9374\n",
      "Epoch 155/300\n",
      "469/469 - 1s - loss: 0.0326 - accuracy: 0.9941 - val_loss: 0.2436 - val_accuracy: 0.9370\n",
      "Epoch 156/300\n",
      "469/469 - 1s - loss: 0.0325 - accuracy: 0.9941 - val_loss: 0.2437 - val_accuracy: 0.9371\n",
      "Epoch 157/300\n",
      "469/469 - 1s - loss: 0.0324 - accuracy: 0.9941 - val_loss: 0.2438 - val_accuracy: 0.9369\n",
      "Epoch 158/300\n",
      "469/469 - 1s - loss: 0.0324 - accuracy: 0.9942 - val_loss: 0.2444 - val_accuracy: 0.9366\n",
      "Epoch 159/300\n",
      "469/469 - 1s - loss: 0.0323 - accuracy: 0.9941 - val_loss: 0.2456 - val_accuracy: 0.9370\n",
      "Epoch 160/300\n",
      "469/469 - 1s - loss: 0.0323 - accuracy: 0.9942 - val_loss: 0.2440 - val_accuracy: 0.9371\n",
      "Epoch 161/300\n",
      "469/469 - 1s - loss: 0.0323 - accuracy: 0.9940 - val_loss: 0.2445 - val_accuracy: 0.9369\n",
      "Epoch 162/300\n",
      "469/469 - 1s - loss: 0.0322 - accuracy: 0.9943 - val_loss: 0.2453 - val_accuracy: 0.9372\n",
      "Epoch 163/300\n",
      "469/469 - 1s - loss: 0.0322 - accuracy: 0.9944 - val_loss: 0.2451 - val_accuracy: 0.9370\n",
      "Epoch 164/300\n",
      "469/469 - 1s - loss: 0.0321 - accuracy: 0.9944 - val_loss: 0.2447 - val_accuracy: 0.9364\n",
      "Epoch 165/300\n",
      "469/469 - 1s - loss: 0.0321 - accuracy: 0.9944 - val_loss: 0.2450 - val_accuracy: 0.9373\n",
      "Epoch 166/300\n",
      "469/469 - 1s - loss: 0.0320 - accuracy: 0.9945 - val_loss: 0.2456 - val_accuracy: 0.9373\n",
      "Epoch 167/300\n",
      "469/469 - 1s - loss: 0.0320 - accuracy: 0.9942 - val_loss: 0.2450 - val_accuracy: 0.9371\n",
      "Epoch 168/300\n",
      "469/469 - 1s - loss: 0.0319 - accuracy: 0.9943 - val_loss: 0.2452 - val_accuracy: 0.9371\n",
      "Epoch 169/300\n",
      "469/469 - 1s - loss: 0.0318 - accuracy: 0.9942 - val_loss: 0.2461 - val_accuracy: 0.9366\n",
      "Epoch 170/300\n",
      "469/469 - 1s - loss: 0.0318 - accuracy: 0.9943 - val_loss: 0.2461 - val_accuracy: 0.9370\n",
      "Epoch 171/300\n",
      "469/469 - 1s - loss: 0.0318 - accuracy: 0.9944 - val_loss: 0.2464 - val_accuracy: 0.9367\n",
      "Epoch 172/300\n",
      "469/469 - 1s - loss: 0.0317 - accuracy: 0.9944 - val_loss: 0.2457 - val_accuracy: 0.9369\n",
      "Epoch 173/300\n",
      "469/469 - 1s - loss: 0.0317 - accuracy: 0.9944 - val_loss: 0.2460 - val_accuracy: 0.9369\n",
      "Epoch 174/300\n",
      "469/469 - 1s - loss: 0.0316 - accuracy: 0.9944 - val_loss: 0.2462 - val_accuracy: 0.9371\n",
      "Epoch 175/300\n",
      "469/469 - 1s - loss: 0.0316 - accuracy: 0.9946 - val_loss: 0.2465 - val_accuracy: 0.9368\n",
      "Epoch 176/300\n",
      "469/469 - 1s - loss: 0.0315 - accuracy: 0.9944 - val_loss: 0.2474 - val_accuracy: 0.9368\n",
      "Epoch 177/300\n",
      "469/469 - 1s - loss: 0.0315 - accuracy: 0.9944 - val_loss: 0.2479 - val_accuracy: 0.9363\n",
      "Epoch 178/300\n",
      "469/469 - 1s - loss: 0.0314 - accuracy: 0.9944 - val_loss: 0.2468 - val_accuracy: 0.9372\n",
      "Epoch 179/300\n",
      "469/469 - 1s - loss: 0.0313 - accuracy: 0.9946 - val_loss: 0.2469 - val_accuracy: 0.9373\n",
      "Epoch 180/300\n",
      "469/469 - 1s - loss: 0.0313 - accuracy: 0.9947 - val_loss: 0.2474 - val_accuracy: 0.9367\n",
      "Epoch 181/300\n",
      "469/469 - 1s - loss: 0.0313 - accuracy: 0.9946 - val_loss: 0.2482 - val_accuracy: 0.9367\n",
      "Epoch 182/300\n",
      "469/469 - 1s - loss: 0.0312 - accuracy: 0.9946 - val_loss: 0.2482 - val_accuracy: 0.9372\n",
      "Epoch 183/300\n",
      "469/469 - 1s - loss: 0.0312 - accuracy: 0.9947 - val_loss: 0.2483 - val_accuracy: 0.9368\n",
      "Epoch 184/300\n",
      "469/469 - 1s - loss: 0.0311 - accuracy: 0.9948 - val_loss: 0.2480 - val_accuracy: 0.9370\n",
      "Epoch 185/300\n",
      "469/469 - 1s - loss: 0.0311 - accuracy: 0.9948 - val_loss: 0.2483 - val_accuracy: 0.9364\n",
      "Epoch 186/300\n",
      "469/469 - 1s - loss: 0.0310 - accuracy: 0.9946 - val_loss: 0.2480 - val_accuracy: 0.9371\n",
      "Epoch 187/300\n",
      "469/469 - 1s - loss: 0.0309 - accuracy: 0.9947 - val_loss: 0.2485 - val_accuracy: 0.9362\n",
      "Epoch 188/300\n",
      "469/469 - 1s - loss: 0.0310 - accuracy: 0.9947 - val_loss: 0.2489 - val_accuracy: 0.9368\n",
      "Epoch 189/300\n",
      "469/469 - 1s - loss: 0.0309 - accuracy: 0.9947 - val_loss: 0.2496 - val_accuracy: 0.9359\n",
      "Epoch 190/300\n",
      "469/469 - 1s - loss: 0.0308 - accuracy: 0.9945 - val_loss: 0.2491 - val_accuracy: 0.9369\n",
      "Epoch 191/300\n",
      "469/469 - 1s - loss: 0.0308 - accuracy: 0.9948 - val_loss: 0.2490 - val_accuracy: 0.9371\n",
      "Epoch 192/300\n",
      "469/469 - 1s - loss: 0.0307 - accuracy: 0.9948 - val_loss: 0.2503 - val_accuracy: 0.9365\n",
      "Epoch 193/300\n",
      "469/469 - 1s - loss: 0.0307 - accuracy: 0.9947 - val_loss: 0.2492 - val_accuracy: 0.9367\n",
      "Epoch 194/300\n",
      "469/469 - 1s - loss: 0.0307 - accuracy: 0.9948 - val_loss: 0.2501 - val_accuracy: 0.9364\n",
      "Epoch 195/300\n",
      "469/469 - 1s - loss: 0.0306 - accuracy: 0.9948 - val_loss: 0.2502 - val_accuracy: 0.9368\n",
      "Epoch 196/300\n",
      "469/469 - 1s - loss: 0.0306 - accuracy: 0.9946 - val_loss: 0.2498 - val_accuracy: 0.9364\n",
      "Epoch 197/300\n",
      "469/469 - 1s - loss: 0.0305 - accuracy: 0.9948 - val_loss: 0.2510 - val_accuracy: 0.9365\n",
      "Epoch 198/300\n",
      "469/469 - 1s - loss: 0.0305 - accuracy: 0.9946 - val_loss: 0.2507 - val_accuracy: 0.9365\n",
      "Epoch 199/300\n",
      "469/469 - 1s - loss: 0.0304 - accuracy: 0.9948 - val_loss: 0.2502 - val_accuracy: 0.9363\n",
      "Epoch 200/300\n",
      "469/469 - 1s - loss: 0.0304 - accuracy: 0.9948 - val_loss: 0.2515 - val_accuracy: 0.9364\n",
      "Epoch 201/300\n",
      "469/469 - 1s - loss: 0.0304 - accuracy: 0.9949 - val_loss: 0.2508 - val_accuracy: 0.9363\n",
      "Epoch 202/300\n",
      "469/469 - 1s - loss: 0.0303 - accuracy: 0.9948 - val_loss: 0.2513 - val_accuracy: 0.9364\n",
      "Epoch 203/300\n",
      "469/469 - 1s - loss: 0.0303 - accuracy: 0.9948 - val_loss: 0.2516 - val_accuracy: 0.9363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 204/300\n",
      "469/469 - 1s - loss: 0.0302 - accuracy: 0.9948 - val_loss: 0.2523 - val_accuracy: 0.9362\n",
      "Epoch 205/300\n",
      "469/469 - 1s - loss: 0.0302 - accuracy: 0.9949 - val_loss: 0.2514 - val_accuracy: 0.9371\n",
      "Epoch 206/300\n",
      "469/469 - 1s - loss: 0.0301 - accuracy: 0.9950 - val_loss: 0.2522 - val_accuracy: 0.9362\n",
      "Epoch 207/300\n",
      "469/469 - 1s - loss: 0.0300 - accuracy: 0.9949 - val_loss: 0.2522 - val_accuracy: 0.9376\n",
      "Epoch 208/300\n",
      "469/469 - 1s - loss: 0.0300 - accuracy: 0.9948 - val_loss: 0.2530 - val_accuracy: 0.9367\n",
      "Epoch 209/300\n",
      "469/469 - 1s - loss: 0.0299 - accuracy: 0.9949 - val_loss: 0.2531 - val_accuracy: 0.9360\n",
      "Epoch 210/300\n",
      "469/469 - 1s - loss: 0.0299 - accuracy: 0.9949 - val_loss: 0.2533 - val_accuracy: 0.9359\n",
      "Epoch 211/300\n",
      "469/469 - 1s - loss: 0.0299 - accuracy: 0.9949 - val_loss: 0.2542 - val_accuracy: 0.9361\n",
      "Epoch 212/300\n",
      "469/469 - 1s - loss: 0.0298 - accuracy: 0.9949 - val_loss: 0.2527 - val_accuracy: 0.9363\n",
      "Epoch 213/300\n",
      "469/469 - 1s - loss: 0.0298 - accuracy: 0.9950 - val_loss: 0.2537 - val_accuracy: 0.9364\n",
      "Epoch 214/300\n",
      "469/469 - 1s - loss: 0.0297 - accuracy: 0.9950 - val_loss: 0.2548 - val_accuracy: 0.9356\n",
      "Epoch 215/300\n",
      "469/469 - 1s - loss: 0.0297 - accuracy: 0.9951 - val_loss: 0.2537 - val_accuracy: 0.9361\n",
      "Epoch 216/300\n",
      "469/469 - 1s - loss: 0.0297 - accuracy: 0.9951 - val_loss: 0.2535 - val_accuracy: 0.9368\n",
      "Epoch 217/300\n",
      "469/469 - 1s - loss: 0.0296 - accuracy: 0.9950 - val_loss: 0.2550 - val_accuracy: 0.9360\n",
      "Epoch 218/300\n",
      "469/469 - 1s - loss: 0.0295 - accuracy: 0.9951 - val_loss: 0.2541 - val_accuracy: 0.9362\n",
      "Epoch 219/300\n",
      "469/469 - 1s - loss: 0.0295 - accuracy: 0.9950 - val_loss: 0.2540 - val_accuracy: 0.9366\n",
      "Epoch 220/300\n",
      "469/469 - 1s - loss: 0.0295 - accuracy: 0.9951 - val_loss: 0.2546 - val_accuracy: 0.9368\n",
      "Epoch 221/300\n",
      "469/469 - 1s - loss: 0.0295 - accuracy: 0.9951 - val_loss: 0.2552 - val_accuracy: 0.9373\n",
      "Epoch 222/300\n",
      "469/469 - 1s - loss: 0.0294 - accuracy: 0.9951 - val_loss: 0.2560 - val_accuracy: 0.9364\n",
      "Epoch 223/300\n",
      "469/469 - 1s - loss: 0.0294 - accuracy: 0.9951 - val_loss: 0.2558 - val_accuracy: 0.9358\n",
      "Epoch 224/300\n",
      "469/469 - 1s - loss: 0.0293 - accuracy: 0.9951 - val_loss: 0.2566 - val_accuracy: 0.9354\n",
      "Epoch 225/300\n",
      "469/469 - 1s - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.2555 - val_accuracy: 0.9360\n",
      "Epoch 226/300\n",
      "469/469 - 1s - loss: 0.0292 - accuracy: 0.9951 - val_loss: 0.2562 - val_accuracy: 0.9364\n",
      "Epoch 227/300\n",
      "469/469 - 1s - loss: 0.0291 - accuracy: 0.9953 - val_loss: 0.2560 - val_accuracy: 0.9353\n",
      "Epoch 228/300\n",
      "469/469 - 1s - loss: 0.0291 - accuracy: 0.9952 - val_loss: 0.2557 - val_accuracy: 0.9360\n",
      "Epoch 229/300\n",
      "469/469 - 1s - loss: 0.0291 - accuracy: 0.9952 - val_loss: 0.2565 - val_accuracy: 0.9358\n",
      "Epoch 230/300\n",
      "469/469 - 1s - loss: 0.0290 - accuracy: 0.9951 - val_loss: 0.2562 - val_accuracy: 0.9362\n",
      "Epoch 231/300\n",
      "469/469 - 1s - loss: 0.0290 - accuracy: 0.9952 - val_loss: 0.2571 - val_accuracy: 0.9359\n",
      "Epoch 232/300\n",
      "469/469 - 1s - loss: 0.0289 - accuracy: 0.9953 - val_loss: 0.2573 - val_accuracy: 0.9355\n",
      "Epoch 233/300\n",
      "469/469 - 1s - loss: 0.0289 - accuracy: 0.9952 - val_loss: 0.2577 - val_accuracy: 0.9354\n",
      "Epoch 234/300\n",
      "469/469 - 1s - loss: 0.0289 - accuracy: 0.9952 - val_loss: 0.2573 - val_accuracy: 0.9359\n",
      "Epoch 235/300\n",
      "469/469 - 1s - loss: 0.0288 - accuracy: 0.9954 - val_loss: 0.2570 - val_accuracy: 0.9361\n",
      "Epoch 236/300\n",
      "469/469 - 1s - loss: 0.0288 - accuracy: 0.9953 - val_loss: 0.2582 - val_accuracy: 0.9360\n",
      "Epoch 237/300\n",
      "469/469 - 1s - loss: 0.0287 - accuracy: 0.9954 - val_loss: 0.2581 - val_accuracy: 0.9358\n",
      "Epoch 238/300\n",
      "469/469 - 1s - loss: 0.0287 - accuracy: 0.9953 - val_loss: 0.2582 - val_accuracy: 0.9353\n",
      "Epoch 239/300\n",
      "469/469 - 1s - loss: 0.0286 - accuracy: 0.9954 - val_loss: 0.2574 - val_accuracy: 0.9358\n",
      "Epoch 240/300\n",
      "469/469 - 1s - loss: 0.0285 - accuracy: 0.9954 - val_loss: 0.2586 - val_accuracy: 0.9361\n",
      "Epoch 241/300\n",
      "469/469 - 1s - loss: 0.0286 - accuracy: 0.9955 - val_loss: 0.2582 - val_accuracy: 0.9361\n",
      "Epoch 242/300\n",
      "469/469 - 1s - loss: 0.0285 - accuracy: 0.9955 - val_loss: 0.2591 - val_accuracy: 0.9362\n",
      "Epoch 243/300\n",
      "469/469 - 1s - loss: 0.0285 - accuracy: 0.9954 - val_loss: 0.2588 - val_accuracy: 0.9357\n",
      "Epoch 244/300\n",
      "469/469 - 1s - loss: 0.0284 - accuracy: 0.9954 - val_loss: 0.2591 - val_accuracy: 0.9355\n",
      "Epoch 245/300\n",
      "469/469 - 1s - loss: 0.0283 - accuracy: 0.9955 - val_loss: 0.2597 - val_accuracy: 0.9359\n",
      "Epoch 246/300\n",
      "469/469 - 1s - loss: 0.0283 - accuracy: 0.9954 - val_loss: 0.2606 - val_accuracy: 0.9355\n",
      "Epoch 247/300\n",
      "469/469 - 1s - loss: 0.0283 - accuracy: 0.9955 - val_loss: 0.2591 - val_accuracy: 0.9361\n",
      "Epoch 248/300\n",
      "469/469 - 1s - loss: 0.0282 - accuracy: 0.9955 - val_loss: 0.2608 - val_accuracy: 0.9362\n",
      "Epoch 249/300\n",
      "469/469 - 1s - loss: 0.0282 - accuracy: 0.9955 - val_loss: 0.2603 - val_accuracy: 0.9356\n",
      "Epoch 250/300\n",
      "469/469 - 1s - loss: 0.0282 - accuracy: 0.9955 - val_loss: 0.2602 - val_accuracy: 0.9360\n",
      "Epoch 251/300\n",
      "469/469 - 1s - loss: 0.0281 - accuracy: 0.9955 - val_loss: 0.2608 - val_accuracy: 0.9359\n",
      "Epoch 252/300\n",
      "469/469 - 1s - loss: 0.0281 - accuracy: 0.9954 - val_loss: 0.2602 - val_accuracy: 0.9362\n",
      "Epoch 253/300\n",
      "469/469 - 1s - loss: 0.0281 - accuracy: 0.9956 - val_loss: 0.2611 - val_accuracy: 0.9353\n",
      "Epoch 254/300\n",
      "469/469 - 1s - loss: 0.0279 - accuracy: 0.9955 - val_loss: 0.2612 - val_accuracy: 0.9356\n",
      "Epoch 255/300\n",
      "469/469 - 1s - loss: 0.0280 - accuracy: 0.9955 - val_loss: 0.2606 - val_accuracy: 0.9363\n",
      "Epoch 256/300\n",
      "469/469 - 1s - loss: 0.0279 - accuracy: 0.9956 - val_loss: 0.2608 - val_accuracy: 0.9360\n",
      "Epoch 257/300\n",
      "469/469 - 1s - loss: 0.0279 - accuracy: 0.9955 - val_loss: 0.2613 - val_accuracy: 0.9359\n",
      "Epoch 258/300\n",
      "469/469 - 1s - loss: 0.0278 - accuracy: 0.9955 - val_loss: 0.2610 - val_accuracy: 0.9357\n",
      "Epoch 259/300\n",
      "469/469 - 1s - loss: 0.0278 - accuracy: 0.9956 - val_loss: 0.2622 - val_accuracy: 0.9355\n",
      "Epoch 260/300\n",
      "469/469 - 1s - loss: 0.0278 - accuracy: 0.9955 - val_loss: 0.2622 - val_accuracy: 0.9359\n",
      "Epoch 261/300\n",
      "469/469 - 1s - loss: 0.0277 - accuracy: 0.9956 - val_loss: 0.2626 - val_accuracy: 0.9357\n",
      "Epoch 262/300\n",
      "469/469 - 1s - loss: 0.0277 - accuracy: 0.9956 - val_loss: 0.2627 - val_accuracy: 0.9360\n",
      "Epoch 263/300\n",
      "469/469 - 1s - loss: 0.0277 - accuracy: 0.9956 - val_loss: 0.2624 - val_accuracy: 0.9360\n",
      "Epoch 264/300\n",
      "469/469 - 1s - loss: 0.0276 - accuracy: 0.9956 - val_loss: 0.2621 - val_accuracy: 0.9360\n",
      "Epoch 265/300\n",
      "469/469 - 1s - loss: 0.0276 - accuracy: 0.9955 - val_loss: 0.2628 - val_accuracy: 0.9354\n",
      "Epoch 266/300\n",
      "469/469 - 1s - loss: 0.0276 - accuracy: 0.9956 - val_loss: 0.2639 - val_accuracy: 0.9354\n",
      "Epoch 267/300\n",
      "469/469 - 1s - loss: 0.0275 - accuracy: 0.9957 - val_loss: 0.2637 - val_accuracy: 0.9349\n",
      "Epoch 268/300\n",
      "469/469 - 1s - loss: 0.0275 - accuracy: 0.9957 - val_loss: 0.2628 - val_accuracy: 0.9358\n",
      "Epoch 269/300\n",
      "469/469 - 1s - loss: 0.0274 - accuracy: 0.9957 - val_loss: 0.2642 - val_accuracy: 0.9359\n",
      "Epoch 270/300\n",
      "469/469 - 1s - loss: 0.0274 - accuracy: 0.9959 - val_loss: 0.2638 - val_accuracy: 0.9355\n",
      "Epoch 271/300\n",
      "469/469 - 1s - loss: 0.0273 - accuracy: 0.9955 - val_loss: 0.2645 - val_accuracy: 0.9363\n",
      "Epoch 272/300\n",
      "469/469 - 1s - loss: 0.0273 - accuracy: 0.9957 - val_loss: 0.2656 - val_accuracy: 0.9358\n",
      "Epoch 273/300\n",
      "469/469 - 1s - loss: 0.0272 - accuracy: 0.9957 - val_loss: 0.2642 - val_accuracy: 0.9355\n",
      "Epoch 274/300\n",
      "469/469 - 1s - loss: 0.0272 - accuracy: 0.9957 - val_loss: 0.2651 - val_accuracy: 0.9356\n",
      "Epoch 275/300\n",
      "469/469 - 1s - loss: 0.0272 - accuracy: 0.9958 - val_loss: 0.2654 - val_accuracy: 0.9353\n",
      "Epoch 276/300\n",
      "469/469 - 1s - loss: 0.0271 - accuracy: 0.9959 - val_loss: 0.2643 - val_accuracy: 0.9357\n",
      "Epoch 277/300\n",
      "469/469 - 1s - loss: 0.0271 - accuracy: 0.9959 - val_loss: 0.2648 - val_accuracy: 0.9357\n",
      "Epoch 278/300\n",
      "469/469 - 1s - loss: 0.0271 - accuracy: 0.9959 - val_loss: 0.2646 - val_accuracy: 0.9357\n",
      "Epoch 279/300\n",
      "469/469 - 1s - loss: 0.0271 - accuracy: 0.9958 - val_loss: 0.2655 - val_accuracy: 0.9353\n",
      "Epoch 280/300\n",
      "469/469 - 1s - loss: 0.0270 - accuracy: 0.9958 - val_loss: 0.2656 - val_accuracy: 0.9355\n",
      "Epoch 281/300\n",
      "469/469 - 1s - loss: 0.0270 - accuracy: 0.9958 - val_loss: 0.2657 - val_accuracy: 0.9353\n",
      "Epoch 282/300\n",
      "469/469 - 1s - loss: 0.0269 - accuracy: 0.9959 - val_loss: 0.2660 - val_accuracy: 0.9360\n",
      "Epoch 283/300\n",
      "469/469 - 1s - loss: 0.0269 - accuracy: 0.9958 - val_loss: 0.2658 - val_accuracy: 0.9358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/300\n",
      "469/469 - 1s - loss: 0.0268 - accuracy: 0.9959 - val_loss: 0.2668 - val_accuracy: 0.9357\n",
      "Epoch 285/300\n",
      "469/469 - 1s - loss: 0.0268 - accuracy: 0.9959 - val_loss: 0.2662 - val_accuracy: 0.9354\n",
      "Epoch 286/300\n",
      "469/469 - 1s - loss: 0.0268 - accuracy: 0.9959 - val_loss: 0.2678 - val_accuracy: 0.9353\n",
      "Epoch 287/300\n",
      "469/469 - 1s - loss: 0.0267 - accuracy: 0.9959 - val_loss: 0.2666 - val_accuracy: 0.9351\n",
      "Epoch 288/300\n",
      "469/469 - 1s - loss: 0.0267 - accuracy: 0.9960 - val_loss: 0.2676 - val_accuracy: 0.9345\n",
      "Epoch 289/300\n",
      "469/469 - 1s - loss: 0.0266 - accuracy: 0.9959 - val_loss: 0.2677 - val_accuracy: 0.9348\n",
      "Epoch 290/300\n",
      "469/469 - 1s - loss: 0.0266 - accuracy: 0.9958 - val_loss: 0.2680 - val_accuracy: 0.9346\n",
      "Epoch 291/300\n",
      "469/469 - 1s - loss: 0.0266 - accuracy: 0.9960 - val_loss: 0.2676 - val_accuracy: 0.9350\n",
      "Epoch 292/300\n",
      "469/469 - 1s - loss: 0.0264 - accuracy: 0.9959 - val_loss: 0.2684 - val_accuracy: 0.9349\n",
      "Epoch 293/300\n",
      "469/469 - 1s - loss: 0.0265 - accuracy: 0.9959 - val_loss: 0.2679 - val_accuracy: 0.9356\n",
      "Epoch 294/300\n",
      "469/469 - 1s - loss: 0.0264 - accuracy: 0.9959 - val_loss: 0.2681 - val_accuracy: 0.9351\n",
      "Epoch 295/300\n",
      "469/469 - 1s - loss: 0.0264 - accuracy: 0.9960 - val_loss: 0.2684 - val_accuracy: 0.9348\n",
      "Epoch 296/300\n",
      "469/469 - 1s - loss: 0.0264 - accuracy: 0.9960 - val_loss: 0.2688 - val_accuracy: 0.9355\n",
      "Epoch 297/300\n",
      "469/469 - 1s - loss: 0.0264 - accuracy: 0.9959 - val_loss: 0.2685 - val_accuracy: 0.9349\n",
      "Epoch 298/300\n",
      "469/469 - 1s - loss: 0.0263 - accuracy: 0.9961 - val_loss: 0.2681 - val_accuracy: 0.9347\n",
      "Epoch 299/300\n",
      "469/469 - 1s - loss: 0.0263 - accuracy: 0.9960 - val_loss: 0.2694 - val_accuracy: 0.9344\n",
      "Epoch 300/300\n",
      "469/469 - 1s - loss: 0.0262 - accuracy: 0.9959 - val_loss: 0.2690 - val_accuracy: 0.9348\n",
      "Epoch 1/300\n",
      "469/469 - 1s - loss: 0.0256 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9348\n",
      "Epoch 2/300\n",
      "469/469 - 1s - loss: 0.0256 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9349\n",
      "Epoch 3/300\n",
      "469/469 - 1s - loss: 0.0256 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9352\n",
      "Epoch 4/300\n",
      "469/469 - 1s - loss: 0.0256 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9350\n",
      "Epoch 5/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9349\n",
      "Epoch 6/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9350\n",
      "Epoch 7/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9348\n",
      "Epoch 8/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9349\n",
      "Epoch 9/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9349\n",
      "Epoch 10/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9349\n",
      "Epoch 11/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9350\n",
      "Epoch 12/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9351\n",
      "Epoch 13/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9352\n",
      "Epoch 14/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9352\n",
      "Epoch 15/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9352\n",
      "Epoch 16/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9352\n",
      "Epoch 17/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9352\n",
      "Epoch 18/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9352\n",
      "Epoch 19/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9353\n",
      "Epoch 20/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9353\n",
      "Epoch 21/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9353\n",
      "Epoch 22/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9353\n",
      "Epoch 23/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 24/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 25/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 26/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 27/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 28/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 29/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 30/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 31/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 32/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 33/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 34/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 35/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 36/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 37/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 38/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 39/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 40/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 41/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 42/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 43/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 44/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 45/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 46/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 47/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 48/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 49/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 50/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 51/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 52/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 53/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 54/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 55/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 56/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 57/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 58/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 59/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 60/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 61/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9355\n",
      "Epoch 62/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 63/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 64/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 66/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 67/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 68/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 69/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 70/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 71/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 72/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 73/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 74/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 75/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 76/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 77/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 78/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 79/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 80/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 81/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 82/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 83/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 84/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 85/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 86/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 87/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 88/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 89/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2689 - val_accuracy: 0.9354\n",
      "Epoch 90/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 91/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 92/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 93/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 94/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 95/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 96/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 97/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 98/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 99/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 100/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 101/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 102/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 103/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 104/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 105/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 106/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 107/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 108/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 109/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 110/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 111/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9355\n",
      "Epoch 112/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 113/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 114/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 115/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 116/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 117/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 118/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 119/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 120/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 121/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 122/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 123/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 124/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 125/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 126/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 127/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 128/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 129/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 130/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 131/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 132/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 133/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 134/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 135/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 136/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 137/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 138/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 139/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 140/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 141/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 142/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 143/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 144/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 146/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 147/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 148/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 149/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 150/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 151/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9354\n",
      "Epoch 152/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9353\n",
      "Epoch 153/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9353\n",
      "Epoch 154/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9353\n",
      "Epoch 155/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9353\n",
      "Epoch 156/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9353\n",
      "Epoch 157/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2690 - val_accuracy: 0.9353\n",
      "Epoch 158/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2690 - val_accuracy: 0.9353\n",
      "Epoch 159/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 160/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 161/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 162/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 163/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 164/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 165/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 166/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 167/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 168/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 169/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 170/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 171/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 172/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 173/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 174/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 175/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 176/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 177/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 178/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 179/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 180/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 181/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 182/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 183/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 184/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 185/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 186/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 187/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 188/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 189/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 190/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 191/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 192/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 193/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 194/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 195/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 196/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 197/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 198/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 199/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 200/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 201/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 202/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 203/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 204/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 205/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 206/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 207/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 208/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 209/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 210/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 211/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 212/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 213/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 214/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 215/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 216/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 217/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 218/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 219/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 220/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 221/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 222/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 223/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 224/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 226/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 227/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 228/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 229/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 230/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 231/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2691 - val_accuracy: 0.9353\n",
      "Epoch 232/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 233/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 234/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 235/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 236/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 237/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 238/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 239/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 240/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 241/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 242/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 243/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 244/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 245/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 246/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 247/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 248/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 249/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 250/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9353\n",
      "Epoch 251/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 252/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 253/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 254/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 255/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 256/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 257/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 258/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 259/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 260/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 261/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 262/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 263/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 264/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 265/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 266/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 267/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 268/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 269/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 270/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 271/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 272/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 273/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 274/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 275/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 276/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 277/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 278/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 279/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 280/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 281/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 282/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 283/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 284/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 285/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 286/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 287/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 288/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 289/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 290/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 291/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 292/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 293/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 294/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 295/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 296/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 297/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 298/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 299/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 300/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2692 - val_accuracy: 0.9354\n",
      "Epoch 1/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2693 - val_accuracy: 0.9351\n",
      "Epoch 2/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2692 - val_accuracy: 0.9357\n",
      "Epoch 3/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9354\n",
      "Epoch 4/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 0.2694 - val_accuracy: 0.9354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9349\n",
      "Epoch 6/300\n",
      "469/469 - 1s - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9351\n",
      "Epoch 7/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2693 - val_accuracy: 0.9352\n",
      "Epoch 8/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9348\n",
      "Epoch 9/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9354\n",
      "Epoch 10/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9348\n",
      "Epoch 11/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9353\n",
      "Epoch 12/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2698 - val_accuracy: 0.9350\n",
      "Epoch 13/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9963 - val_loss: 0.2696 - val_accuracy: 0.9357\n",
      "Epoch 14/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2695 - val_accuracy: 0.9351\n",
      "Epoch 15/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2696 - val_accuracy: 0.9351\n",
      "Epoch 16/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2698 - val_accuracy: 0.9350\n",
      "Epoch 17/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2700 - val_accuracy: 0.9349\n",
      "Epoch 18/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2699 - val_accuracy: 0.9351\n",
      "Epoch 19/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2697 - val_accuracy: 0.9349\n",
      "Epoch 20/300\n",
      "469/469 - 1s - loss: 0.0254 - accuracy: 0.9964 - val_loss: 0.2699 - val_accuracy: 0.9351\n",
      "Epoch 21/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2699 - val_accuracy: 0.9348\n",
      "Epoch 22/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2701 - val_accuracy: 0.9350\n",
      "Epoch 23/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2701 - val_accuracy: 0.9349\n",
      "Epoch 24/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2700 - val_accuracy: 0.9349\n",
      "Epoch 25/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2700 - val_accuracy: 0.9348\n",
      "Epoch 26/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2701 - val_accuracy: 0.9350\n",
      "Epoch 27/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2699 - val_accuracy: 0.9349\n",
      "Epoch 28/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2699 - val_accuracy: 0.9349\n",
      "Epoch 29/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2702 - val_accuracy: 0.9349\n",
      "Epoch 30/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2700 - val_accuracy: 0.9349\n",
      "Epoch 31/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2701 - val_accuracy: 0.9347\n",
      "Epoch 32/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2705 - val_accuracy: 0.9351\n",
      "Epoch 33/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9966 - val_loss: 0.2705 - val_accuracy: 0.9351\n",
      "Epoch 34/300\n",
      "469/469 - 1s - loss: 0.0253 - accuracy: 0.9965 - val_loss: 0.2701 - val_accuracy: 0.9347\n",
      "Epoch 35/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.2704 - val_accuracy: 0.9352\n",
      "Epoch 36/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2703 - val_accuracy: 0.9348\n",
      "Epoch 37/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2704 - val_accuracy: 0.9348\n",
      "Epoch 38/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2703 - val_accuracy: 0.9348\n",
      "Epoch 39/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.2703 - val_accuracy: 0.9347\n",
      "Epoch 40/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9964 - val_loss: 0.2704 - val_accuracy: 0.9349\n",
      "Epoch 41/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.2706 - val_accuracy: 0.9350\n",
      "Epoch 42/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.2704 - val_accuracy: 0.9350\n",
      "Epoch 43/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2706 - val_accuracy: 0.9345\n",
      "Epoch 44/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.2706 - val_accuracy: 0.9346\n",
      "Epoch 45/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2705 - val_accuracy: 0.9345\n",
      "Epoch 46/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9965 - val_loss: 0.2708 - val_accuracy: 0.9345\n",
      "Epoch 47/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2706 - val_accuracy: 0.9345\n",
      "Epoch 48/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2707 - val_accuracy: 0.9349\n",
      "Epoch 49/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2707 - val_accuracy: 0.9349\n",
      "Epoch 50/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2705 - val_accuracy: 0.9349\n",
      "Epoch 51/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2707 - val_accuracy: 0.9347\n",
      "Epoch 52/300\n",
      "469/469 - 1s - loss: 0.0252 - accuracy: 0.9966 - val_loss: 0.2706 - val_accuracy: 0.9350\n",
      "Epoch 53/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.2707 - val_accuracy: 0.9348\n",
      "Epoch 54/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2709 - val_accuracy: 0.9344\n",
      "Epoch 55/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2708 - val_accuracy: 0.9345\n",
      "Epoch 56/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2709 - val_accuracy: 0.9349\n",
      "Epoch 57/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.2710 - val_accuracy: 0.9348\n",
      "Epoch 58/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2708 - val_accuracy: 0.9351\n",
      "Epoch 59/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2709 - val_accuracy: 0.9343\n",
      "Epoch 60/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.2709 - val_accuracy: 0.9344\n",
      "Epoch 61/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2708 - val_accuracy: 0.9349\n",
      "Epoch 62/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.2712 - val_accuracy: 0.9349\n",
      "Epoch 63/300\n",
      "469/469 - 3s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2708 - val_accuracy: 0.9349\n",
      "Epoch 64/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.2709 - val_accuracy: 0.9347\n",
      "Epoch 65/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.2709 - val_accuracy: 0.9344\n",
      "Epoch 66/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2710 - val_accuracy: 0.9345\n",
      "Epoch 67/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9966 - val_loss: 0.2709 - val_accuracy: 0.9347\n",
      "Epoch 68/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2710 - val_accuracy: 0.9347\n",
      "Epoch 69/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2712 - val_accuracy: 0.9343\n",
      "Epoch 70/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2714 - val_accuracy: 0.9348\n",
      "Epoch 71/300\n",
      "469/469 - 1s - loss: 0.0251 - accuracy: 0.9967 - val_loss: 0.2713 - val_accuracy: 0.9347\n",
      "Epoch 72/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2710 - val_accuracy: 0.9347\n",
      "Epoch 73/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2712 - val_accuracy: 0.9347\n",
      "Epoch 74/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9966 - val_loss: 0.2714 - val_accuracy: 0.9342\n",
      "Epoch 75/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2712 - val_accuracy: 0.9347\n",
      "Epoch 76/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9966 - val_loss: 0.2712 - val_accuracy: 0.9349\n",
      "Epoch 77/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2710 - val_accuracy: 0.9345\n",
      "Epoch 78/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2714 - val_accuracy: 0.9344\n",
      "Epoch 79/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2714 - val_accuracy: 0.9341\n",
      "Epoch 80/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2714 - val_accuracy: 0.9346\n",
      "Epoch 81/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9966 - val_loss: 0.2714 - val_accuracy: 0.9346\n",
      "Epoch 82/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2715 - val_accuracy: 0.9346\n",
      "Epoch 83/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2714 - val_accuracy: 0.9345\n",
      "Epoch 84/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2713 - val_accuracy: 0.9346\n",
      "Epoch 85/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2712 - val_accuracy: 0.9346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2716 - val_accuracy: 0.9347\n",
      "Epoch 87/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2714 - val_accuracy: 0.9347\n",
      "Epoch 88/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9968 - val_loss: 0.2715 - val_accuracy: 0.9345\n",
      "Epoch 89/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9967 - val_loss: 0.2714 - val_accuracy: 0.9346\n",
      "Epoch 90/300\n",
      "469/469 - 1s - loss: 0.0250 - accuracy: 0.9968 - val_loss: 0.2716 - val_accuracy: 0.9347\n",
      "Epoch 91/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2717 - val_accuracy: 0.9341\n",
      "Epoch 92/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9345\n",
      "Epoch 93/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2715 - val_accuracy: 0.9345\n",
      "Epoch 94/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9347\n",
      "Epoch 95/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2715 - val_accuracy: 0.9346\n",
      "Epoch 96/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2715 - val_accuracy: 0.9341\n",
      "Epoch 97/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9346\n",
      "Epoch 98/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2716 - val_accuracy: 0.9345\n",
      "Epoch 99/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2717 - val_accuracy: 0.9347\n",
      "Epoch 100/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2719 - val_accuracy: 0.9340\n",
      "Epoch 101/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9344\n",
      "Epoch 102/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9345\n",
      "Epoch 103/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2719 - val_accuracy: 0.9342\n",
      "Epoch 104/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9967 - val_loss: 0.2717 - val_accuracy: 0.9347\n",
      "Epoch 105/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2718 - val_accuracy: 0.9345\n",
      "Epoch 106/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9341\n",
      "Epoch 107/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9345\n",
      "Epoch 108/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2720 - val_accuracy: 0.9344\n",
      "Epoch 109/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2719 - val_accuracy: 0.9347\n",
      "Epoch 110/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9968 - val_loss: 0.2719 - val_accuracy: 0.9348\n",
      "Epoch 111/300\n",
      "469/469 - 2s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2717 - val_accuracy: 0.9345\n",
      "Epoch 112/300\n",
      "469/469 - 1s - loss: 0.0249 - accuracy: 0.9969 - val_loss: 0.2719 - val_accuracy: 0.9346\n",
      "Epoch 113/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2720 - val_accuracy: 0.9344\n",
      "Epoch 114/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2720 - val_accuracy: 0.9341\n",
      "Epoch 115/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2721 - val_accuracy: 0.9344\n",
      "Epoch 116/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2721 - val_accuracy: 0.9345\n",
      "Epoch 117/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2719 - val_accuracy: 0.9345\n",
      "Epoch 118/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2722 - val_accuracy: 0.9345\n",
      "Epoch 119/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2722 - val_accuracy: 0.9342\n",
      "Epoch 120/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2721 - val_accuracy: 0.9345\n",
      "Epoch 121/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2722 - val_accuracy: 0.9343\n",
      "Epoch 122/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2723 - val_accuracy: 0.9343\n",
      "Epoch 123/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2722 - val_accuracy: 0.9347\n",
      "Epoch 124/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2721 - val_accuracy: 0.9342\n",
      "Epoch 125/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2722 - val_accuracy: 0.9344\n",
      "Epoch 126/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2723 - val_accuracy: 0.9345\n",
      "Epoch 127/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2722 - val_accuracy: 0.9345\n",
      "Epoch 128/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2725 - val_accuracy: 0.9343\n",
      "Epoch 129/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2721 - val_accuracy: 0.9344\n",
      "Epoch 130/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9968 - val_loss: 0.2722 - val_accuracy: 0.9344\n",
      "Epoch 131/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2725 - val_accuracy: 0.9343\n",
      "Epoch 132/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2723 - val_accuracy: 0.9345\n",
      "Epoch 133/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9341\n",
      "Epoch 134/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2727 - val_accuracy: 0.9341\n",
      "Epoch 135/300\n",
      "469/469 - 1s - loss: 0.0248 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9346\n",
      "Epoch 136/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9340\n",
      "Epoch 137/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2726 - val_accuracy: 0.9343\n",
      "Epoch 138/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9347\n",
      "Epoch 139/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9343\n",
      "Epoch 140/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9342\n",
      "Epoch 141/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2730 - val_accuracy: 0.9342\n",
      "Epoch 142/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2724 - val_accuracy: 0.9340\n",
      "Epoch 143/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2725 - val_accuracy: 0.9343\n",
      "Epoch 144/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2725 - val_accuracy: 0.9341\n",
      "Epoch 145/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2727 - val_accuracy: 0.9345\n",
      "Epoch 146/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9970 - val_loss: 0.2727 - val_accuracy: 0.9345\n",
      "Epoch 147/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2726 - val_accuracy: 0.9343\n",
      "Epoch 148/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2727 - val_accuracy: 0.9343\n",
      "Epoch 149/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2728 - val_accuracy: 0.9341\n",
      "Epoch 150/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2728 - val_accuracy: 0.9341\n",
      "Epoch 151/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9970 - val_loss: 0.2729 - val_accuracy: 0.9342\n",
      "Epoch 152/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9968 - val_loss: 0.2728 - val_accuracy: 0.9344\n",
      "Epoch 153/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2727 - val_accuracy: 0.9342\n",
      "Epoch 154/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9968 - val_loss: 0.2727 - val_accuracy: 0.9341\n",
      "Epoch 155/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9969 - val_loss: 0.2727 - val_accuracy: 0.9340\n",
      "Epoch 156/300\n",
      "469/469 - 1s - loss: 0.0247 - accuracy: 0.9970 - val_loss: 0.2728 - val_accuracy: 0.9343\n",
      "Epoch 157/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2729 - val_accuracy: 0.9346\n",
      "Epoch 158/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2729 - val_accuracy: 0.9343\n",
      "Epoch 159/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.2732 - val_accuracy: 0.9340\n",
      "Epoch 160/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2728 - val_accuracy: 0.9338\n",
      "Epoch 161/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2730 - val_accuracy: 0.9344\n",
      "Epoch 162/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2731 - val_accuracy: 0.9344\n",
      "Epoch 163/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2730 - val_accuracy: 0.9342\n",
      "Epoch 164/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.2730 - val_accuracy: 0.9343\n",
      "Epoch 165/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2730 - val_accuracy: 0.9344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2731 - val_accuracy: 0.9344\n",
      "Epoch 167/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.2730 - val_accuracy: 0.9346\n",
      "Epoch 168/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2730 - val_accuracy: 0.9344\n",
      "Epoch 169/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2732 - val_accuracy: 0.9344\n",
      "Epoch 170/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2730 - val_accuracy: 0.9340\n",
      "Epoch 171/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2731 - val_accuracy: 0.9339\n",
      "Epoch 172/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2729 - val_accuracy: 0.9343\n",
      "Epoch 173/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2729 - val_accuracy: 0.9344\n",
      "Epoch 174/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2732 - val_accuracy: 0.9343\n",
      "Epoch 175/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2729 - val_accuracy: 0.9345\n",
      "Epoch 176/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.2733 - val_accuracy: 0.9342\n",
      "Epoch 177/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2733 - val_accuracy: 0.9343\n",
      "Epoch 178/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9969 - val_loss: 0.2732 - val_accuracy: 0.9339\n",
      "Epoch 179/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.2734 - val_accuracy: 0.9340\n",
      "Epoch 180/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.2731 - val_accuracy: 0.9343\n",
      "Epoch 181/300\n",
      "469/469 - 1s - loss: 0.0246 - accuracy: 0.9970 - val_loss: 0.2734 - val_accuracy: 0.9343\n",
      "Epoch 182/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2733 - val_accuracy: 0.9341\n",
      "Epoch 183/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2733 - val_accuracy: 0.9347\n",
      "Epoch 184/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.2732 - val_accuracy: 0.9340\n",
      "Epoch 185/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.2732 - val_accuracy: 0.9341\n",
      "Epoch 186/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2732 - val_accuracy: 0.9343\n",
      "Epoch 187/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2734 - val_accuracy: 0.9346\n",
      "Epoch 188/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.2735 - val_accuracy: 0.9341\n",
      "Epoch 189/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.2735 - val_accuracy: 0.9342\n",
      "Epoch 190/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2734 - val_accuracy: 0.9346\n",
      "Epoch 191/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.2733 - val_accuracy: 0.9341\n",
      "Epoch 192/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2737 - val_accuracy: 0.9344\n",
      "Epoch 193/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2735 - val_accuracy: 0.9340\n",
      "Epoch 194/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2736 - val_accuracy: 0.9344\n",
      "Epoch 195/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2737 - val_accuracy: 0.9347\n",
      "Epoch 196/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2736 - val_accuracy: 0.9344\n",
      "Epoch 197/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2737 - val_accuracy: 0.9345\n",
      "Epoch 198/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2737 - val_accuracy: 0.9343\n",
      "Epoch 199/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2736 - val_accuracy: 0.9345\n",
      "Epoch 200/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2737 - val_accuracy: 0.9345\n",
      "Epoch 201/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2737 - val_accuracy: 0.9344\n",
      "Epoch 202/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2736 - val_accuracy: 0.9341\n",
      "Epoch 203/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9971 - val_loss: 0.2737 - val_accuracy: 0.9342\n",
      "Epoch 204/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9970 - val_loss: 0.2737 - val_accuracy: 0.9340\n",
      "Epoch 205/300\n",
      "469/469 - 1s - loss: 0.0245 - accuracy: 0.9969 - val_loss: 0.2736 - val_accuracy: 0.9343\n",
      "Epoch 206/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9969 - val_loss: 0.2738 - val_accuracy: 0.9342\n",
      "Epoch 207/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2736 - val_accuracy: 0.9338\n",
      "Epoch 208/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9971 - val_loss: 0.2740 - val_accuracy: 0.9342\n",
      "Epoch 209/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2738 - val_accuracy: 0.9347\n",
      "Epoch 210/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2739 - val_accuracy: 0.9341\n",
      "Epoch 211/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9969 - val_loss: 0.2739 - val_accuracy: 0.9343\n",
      "Epoch 212/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2738 - val_accuracy: 0.9341\n",
      "Epoch 213/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2739 - val_accuracy: 0.9344\n",
      "Epoch 214/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2740 - val_accuracy: 0.9342\n",
      "Epoch 215/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2739 - val_accuracy: 0.9339\n",
      "Epoch 216/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2738 - val_accuracy: 0.9343\n",
      "Epoch 217/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2742 - val_accuracy: 0.9341\n",
      "Epoch 218/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2739 - val_accuracy: 0.9338\n",
      "Epoch 219/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2739 - val_accuracy: 0.9343\n",
      "Epoch 220/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2738 - val_accuracy: 0.9343\n",
      "Epoch 221/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2739 - val_accuracy: 0.9342\n",
      "Epoch 222/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2740 - val_accuracy: 0.9345\n",
      "Epoch 223/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2742 - val_accuracy: 0.9345\n",
      "Epoch 224/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2742 - val_accuracy: 0.9344\n",
      "Epoch 225/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2741 - val_accuracy: 0.9344\n",
      "Epoch 226/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9969 - val_loss: 0.2742 - val_accuracy: 0.9343\n",
      "Epoch 227/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2739 - val_accuracy: 0.9344\n",
      "Epoch 228/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2740 - val_accuracy: 0.9345\n",
      "Epoch 229/300\n",
      "469/469 - 1s - loss: 0.0244 - accuracy: 0.9970 - val_loss: 0.2741 - val_accuracy: 0.9344\n",
      "Epoch 230/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2740 - val_accuracy: 0.9345\n",
      "Epoch 231/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2742 - val_accuracy: 0.9343\n",
      "Epoch 232/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2742 - val_accuracy: 0.9347\n",
      "Epoch 233/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2743 - val_accuracy: 0.9341\n",
      "Epoch 234/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2742 - val_accuracy: 0.9341\n",
      "Epoch 235/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2742 - val_accuracy: 0.9343\n",
      "Epoch 236/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2742 - val_accuracy: 0.9345\n",
      "Epoch 237/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2743 - val_accuracy: 0.9347\n",
      "Epoch 238/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2744 - val_accuracy: 0.9345\n",
      "Epoch 239/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2741 - val_accuracy: 0.9343\n",
      "Epoch 240/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2745 - val_accuracy: 0.9344\n",
      "Epoch 241/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2742 - val_accuracy: 0.9341\n",
      "Epoch 242/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2744 - val_accuracy: 0.9344\n",
      "Epoch 243/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2743 - val_accuracy: 0.9340\n",
      "Epoch 244/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2744 - val_accuracy: 0.9343\n",
      "Epoch 245/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2744 - val_accuracy: 0.9343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 246/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2744 - val_accuracy: 0.9340\n",
      "Epoch 247/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2743 - val_accuracy: 0.9341\n",
      "Epoch 248/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2746 - val_accuracy: 0.9347\n",
      "Epoch 249/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2746 - val_accuracy: 0.9340\n",
      "Epoch 250/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2746 - val_accuracy: 0.9344\n",
      "Epoch 251/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2745 - val_accuracy: 0.9343\n",
      "Epoch 252/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2744 - val_accuracy: 0.9343\n",
      "Epoch 253/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2746 - val_accuracy: 0.9344\n",
      "Epoch 254/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2747 - val_accuracy: 0.9345\n",
      "Epoch 255/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2744 - val_accuracy: 0.9341\n",
      "Epoch 256/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9970 - val_loss: 0.2745 - val_accuracy: 0.9337\n",
      "Epoch 257/300\n",
      "469/469 - 1s - loss: 0.0243 - accuracy: 0.9971 - val_loss: 0.2746 - val_accuracy: 0.9343\n",
      "Epoch 258/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2745 - val_accuracy: 0.9342\n",
      "Epoch 259/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2748 - val_accuracy: 0.9341\n",
      "Epoch 260/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2746 - val_accuracy: 0.9347\n",
      "Epoch 261/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2748 - val_accuracy: 0.9342\n",
      "Epoch 262/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2748 - val_accuracy: 0.9346\n",
      "Epoch 263/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2746 - val_accuracy: 0.9341\n",
      "Epoch 264/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2746 - val_accuracy: 0.9343\n",
      "Epoch 265/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2749 - val_accuracy: 0.9343\n",
      "Epoch 266/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2749 - val_accuracy: 0.9345\n",
      "Epoch 267/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2749 - val_accuracy: 0.9344\n",
      "Epoch 268/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2746 - val_accuracy: 0.9345\n",
      "Epoch 269/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2749 - val_accuracy: 0.9343\n",
      "Epoch 270/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2749 - val_accuracy: 0.9340\n",
      "Epoch 271/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2750 - val_accuracy: 0.9345\n",
      "Epoch 272/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2751 - val_accuracy: 0.9341\n",
      "Epoch 273/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2750 - val_accuracy: 0.9344\n",
      "Epoch 274/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2751 - val_accuracy: 0.9346\n",
      "Epoch 275/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2750 - val_accuracy: 0.9347\n",
      "Epoch 276/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2747 - val_accuracy: 0.9343\n",
      "Epoch 277/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2749 - val_accuracy: 0.9345\n",
      "Epoch 278/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2748 - val_accuracy: 0.9341\n",
      "Epoch 279/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2748 - val_accuracy: 0.9341\n",
      "Epoch 280/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2751 - val_accuracy: 0.9345\n",
      "Epoch 281/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9970 - val_loss: 0.2750 - val_accuracy: 0.9345\n",
      "Epoch 282/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2749 - val_accuracy: 0.9343\n",
      "Epoch 283/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2749 - val_accuracy: 0.9345\n",
      "Epoch 284/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2751 - val_accuracy: 0.9346\n",
      "Epoch 285/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9972 - val_loss: 0.2750 - val_accuracy: 0.9338\n",
      "Epoch 286/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9342\n",
      "Epoch 287/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2750 - val_accuracy: 0.9344\n",
      "Epoch 288/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2754 - val_accuracy: 0.9342\n",
      "Epoch 289/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2752 - val_accuracy: 0.9345\n",
      "Epoch 290/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9342\n",
      "Epoch 291/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2752 - val_accuracy: 0.9340\n",
      "Epoch 292/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2755 - val_accuracy: 0.9340\n",
      "Epoch 293/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2752 - val_accuracy: 0.9341\n",
      "Epoch 294/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9346\n",
      "Epoch 295/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2751 - val_accuracy: 0.9345\n",
      "Epoch 296/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2753 - val_accuracy: 0.9343\n",
      "Epoch 297/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9345\n",
      "Epoch 298/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9341\n",
      "Epoch 299/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9340\n",
      "Epoch 300/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2752 - val_accuracy: 0.9341\n",
      "Epoch 1/300\n",
      "469/469 - 1s - loss: 0.0242 - accuracy: 0.9971 - val_loss: 0.2753 - val_accuracy: 0.9345\n",
      "Epoch 2/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9970 - val_loss: 0.2753 - val_accuracy: 0.9337\n",
      "Epoch 3/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2757 - val_accuracy: 0.9345\n",
      "Epoch 4/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2754 - val_accuracy: 0.9344\n",
      "Epoch 5/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9971 - val_loss: 0.2758 - val_accuracy: 0.9342\n",
      "Epoch 6/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2756 - val_accuracy: 0.9341\n",
      "Epoch 7/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2753 - val_accuracy: 0.9341\n",
      "Epoch 8/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2756 - val_accuracy: 0.9342\n",
      "Epoch 9/300\n",
      "469/469 - 1s - loss: 0.0241 - accuracy: 0.9972 - val_loss: 0.2754 - val_accuracy: 0.9342\n",
      "Epoch 10/300\n",
      "469/469 - 1s - loss: 0.0240 - accuracy: 0.9971 - val_loss: 0.2756 - val_accuracy: 0.9339\n",
      "Epoch 11/300\n",
      "469/469 - 1s - loss: 0.0240 - accuracy: 0.9972 - val_loss: 0.2756 - val_accuracy: 0.9340\n",
      "Epoch 12/300\n",
      "469/469 - 1s - loss: 0.0240 - accuracy: 0.9971 - val_loss: 0.2762 - val_accuracy: 0.9342\n",
      "Epoch 13/300\n",
      "469/469 - 1s - loss: 0.0240 - accuracy: 0.9973 - val_loss: 0.2757 - val_accuracy: 0.9345\n",
      "Epoch 14/300\n",
      "469/469 - 1s - loss: 0.0240 - accuracy: 0.9972 - val_loss: 0.2755 - val_accuracy: 0.9345\n",
      "Epoch 15/300\n",
      "469/469 - 1s - loss: 0.0240 - accuracy: 0.9971 - val_loss: 0.2760 - val_accuracy: 0.9339\n",
      "Epoch 16/300\n",
      "469/469 - 1s - loss: 0.0240 - accuracy: 0.9972 - val_loss: 0.2761 - val_accuracy: 0.9344\n",
      "Epoch 17/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.2764 - val_accuracy: 0.9341\n",
      "Epoch 18/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.2761 - val_accuracy: 0.9342\n",
      "Epoch 19/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.2758 - val_accuracy: 0.9341\n",
      "Epoch 20/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9971 - val_loss: 0.2763 - val_accuracy: 0.9341\n",
      "Epoch 21/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.2764 - val_accuracy: 0.9336\n",
      "Epoch 22/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9973 - val_loss: 0.2765 - val_accuracy: 0.9340\n",
      "Epoch 23/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.2766 - val_accuracy: 0.9346\n",
      "Epoch 24/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.2762 - val_accuracy: 0.9343\n",
      "Epoch 25/300\n",
      "469/469 - 1s - loss: 0.0239 - accuracy: 0.9972 - val_loss: 0.2765 - val_accuracy: 0.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9972 - val_loss: 0.2765 - val_accuracy: 0.9339\n",
      "Epoch 27/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9972 - val_loss: 0.2762 - val_accuracy: 0.9339\n",
      "Epoch 28/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9972 - val_loss: 0.2761 - val_accuracy: 0.9346\n",
      "Epoch 29/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9972 - val_loss: 0.2765 - val_accuracy: 0.9338\n",
      "Epoch 30/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9973 - val_loss: 0.2764 - val_accuracy: 0.9342\n",
      "Epoch 31/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9973 - val_loss: 0.2766 - val_accuracy: 0.9339\n",
      "Epoch 32/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9973 - val_loss: 0.2769 - val_accuracy: 0.9341\n",
      "Epoch 33/300\n",
      "469/469 - 1s - loss: 0.0238 - accuracy: 0.9972 - val_loss: 0.2772 - val_accuracy: 0.9340\n",
      "Epoch 34/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9972 - val_loss: 0.2765 - val_accuracy: 0.9337\n",
      "Epoch 35/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9973 - val_loss: 0.2770 - val_accuracy: 0.9344\n",
      "Epoch 36/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9972 - val_loss: 0.2769 - val_accuracy: 0.9344\n",
      "Epoch 37/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9972 - val_loss: 0.2771 - val_accuracy: 0.9338\n",
      "Epoch 38/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9972 - val_loss: 0.2769 - val_accuracy: 0.9342\n",
      "Epoch 39/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9973 - val_loss: 0.2770 - val_accuracy: 0.9342\n",
      "Epoch 40/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9973 - val_loss: 0.2771 - val_accuracy: 0.9343\n",
      "Epoch 41/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9973 - val_loss: 0.2773 - val_accuracy: 0.9340\n",
      "Epoch 42/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9973 - val_loss: 0.2771 - val_accuracy: 0.9343\n",
      "Epoch 43/300\n",
      "469/469 - 1s - loss: 0.0237 - accuracy: 0.9973 - val_loss: 0.2772 - val_accuracy: 0.9340\n",
      "Epoch 44/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9973 - val_loss: 0.2773 - val_accuracy: 0.9338\n",
      "Epoch 45/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9973 - val_loss: 0.2772 - val_accuracy: 0.9338\n",
      "Epoch 46/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9974 - val_loss: 0.2777 - val_accuracy: 0.9342\n",
      "Epoch 47/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9972 - val_loss: 0.2773 - val_accuracy: 0.9343\n",
      "Epoch 48/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9973 - val_loss: 0.2774 - val_accuracy: 0.9346\n",
      "Epoch 49/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9973 - val_loss: 0.2774 - val_accuracy: 0.9340\n",
      "Epoch 50/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9973 - val_loss: 0.2772 - val_accuracy: 0.9339\n",
      "Epoch 51/300\n",
      "469/469 - 1s - loss: 0.0236 - accuracy: 0.9973 - val_loss: 0.2775 - val_accuracy: 0.9339\n",
      "Epoch 52/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9973 - val_loss: 0.2775 - val_accuracy: 0.9338\n",
      "Epoch 53/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9973 - val_loss: 0.2774 - val_accuracy: 0.9337\n",
      "Epoch 54/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9974 - val_loss: 0.2780 - val_accuracy: 0.9341\n",
      "Epoch 55/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9973 - val_loss: 0.2779 - val_accuracy: 0.9340\n",
      "Epoch 56/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9973 - val_loss: 0.2779 - val_accuracy: 0.9342\n",
      "Epoch 57/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9972 - val_loss: 0.2780 - val_accuracy: 0.9342\n",
      "Epoch 58/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9974 - val_loss: 0.2778 - val_accuracy: 0.9338\n",
      "Epoch 59/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9973 - val_loss: 0.2782 - val_accuracy: 0.9342\n",
      "Epoch 60/300\n",
      "469/469 - 1s - loss: 0.0235 - accuracy: 0.9973 - val_loss: 0.2781 - val_accuracy: 0.9343\n",
      "Epoch 61/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9973 - val_loss: 0.2779 - val_accuracy: 0.9337\n",
      "Epoch 62/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9973 - val_loss: 0.2782 - val_accuracy: 0.9342\n",
      "Epoch 63/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9973 - val_loss: 0.2778 - val_accuracy: 0.9337\n",
      "Epoch 64/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9974 - val_loss: 0.2779 - val_accuracy: 0.9340\n",
      "Epoch 65/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9973 - val_loss: 0.2780 - val_accuracy: 0.9342\n",
      "Epoch 66/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9973 - val_loss: 0.2781 - val_accuracy: 0.9338\n",
      "Epoch 67/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9973 - val_loss: 0.2778 - val_accuracy: 0.9341\n",
      "Epoch 68/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9974 - val_loss: 0.2780 - val_accuracy: 0.9343\n",
      "Epoch 69/300\n",
      "469/469 - 1s - loss: 0.0234 - accuracy: 0.9974 - val_loss: 0.2785 - val_accuracy: 0.9338\n",
      "Epoch 70/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9975 - val_loss: 0.2790 - val_accuracy: 0.9343\n",
      "Epoch 71/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9974 - val_loss: 0.2786 - val_accuracy: 0.9340\n",
      "Epoch 72/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9973 - val_loss: 0.2782 - val_accuracy: 0.9341\n",
      "Epoch 73/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9974 - val_loss: 0.2784 - val_accuracy: 0.9342\n",
      "Epoch 74/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9975 - val_loss: 0.2789 - val_accuracy: 0.9341\n",
      "Epoch 75/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9973 - val_loss: 0.2785 - val_accuracy: 0.9344\n",
      "Epoch 76/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9974 - val_loss: 0.2784 - val_accuracy: 0.9338\n",
      "Epoch 77/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9975 - val_loss: 0.2782 - val_accuracy: 0.9343\n",
      "Epoch 78/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9974 - val_loss: 0.2787 - val_accuracy: 0.9342\n",
      "Epoch 79/300\n",
      "469/469 - 1s - loss: 0.0233 - accuracy: 0.9974 - val_loss: 0.2787 - val_accuracy: 0.9337\n",
      "Epoch 80/300\n",
      "469/469 - 1s - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.2791 - val_accuracy: 0.9341\n",
      "Epoch 81/300\n",
      "469/469 - 1s - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.2790 - val_accuracy: 0.9340\n",
      "Epoch 82/300\n",
      "469/469 - 1s - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.2790 - val_accuracy: 0.9341\n",
      "Epoch 83/300\n",
      "469/469 - 1s - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.2789 - val_accuracy: 0.9348\n",
      "Epoch 84/300\n",
      "469/469 - 1s - loss: 0.0232 - accuracy: 0.9975 - val_loss: 0.2786 - val_accuracy: 0.9344\n",
      "Epoch 85/300\n",
      "469/469 - 1s - loss: 0.0232 - accuracy: 0.9975 - val_loss: 0.2785 - val_accuracy: 0.9338\n",
      "Epoch 86/300\n",
      "469/469 - 1s - loss: 0.0232 - accuracy: 0.9974 - val_loss: 0.2795 - val_accuracy: 0.9342\n",
      "Epoch 87/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9974 - val_loss: 0.2789 - val_accuracy: 0.9341\n",
      "Epoch 88/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9974 - val_loss: 0.2789 - val_accuracy: 0.9342\n",
      "Epoch 89/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9973 - val_loss: 0.2788 - val_accuracy: 0.9341\n",
      "Epoch 90/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9975 - val_loss: 0.2793 - val_accuracy: 0.9341\n",
      "Epoch 91/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9974 - val_loss: 0.2793 - val_accuracy: 0.9344\n",
      "Epoch 92/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9975 - val_loss: 0.2795 - val_accuracy: 0.9344\n",
      "Epoch 93/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9973 - val_loss: 0.2792 - val_accuracy: 0.9340\n",
      "Epoch 94/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9974 - val_loss: 0.2794 - val_accuracy: 0.9341\n",
      "Epoch 95/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9975 - val_loss: 0.2791 - val_accuracy: 0.9341\n",
      "Epoch 96/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9975 - val_loss: 0.2792 - val_accuracy: 0.9341\n",
      "Epoch 97/300\n",
      "469/469 - 1s - loss: 0.0231 - accuracy: 0.9975 - val_loss: 0.2796 - val_accuracy: 0.9341\n",
      "Epoch 98/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9975 - val_loss: 0.2795 - val_accuracy: 0.9337\n",
      "Epoch 99/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9976 - val_loss: 0.2794 - val_accuracy: 0.9341\n",
      "Epoch 100/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9974 - val_loss: 0.2798 - val_accuracy: 0.9339\n",
      "Epoch 101/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9974 - val_loss: 0.2794 - val_accuracy: 0.9340\n",
      "Epoch 102/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9975 - val_loss: 0.2796 - val_accuracy: 0.9341\n",
      "Epoch 103/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9975 - val_loss: 0.2799 - val_accuracy: 0.9342\n",
      "Epoch 104/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9975 - val_loss: 0.2793 - val_accuracy: 0.9342\n",
      "Epoch 105/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9976 - val_loss: 0.2798 - val_accuracy: 0.9340\n",
      "Epoch 106/300\n",
      "469/469 - 1s - loss: 0.0230 - accuracy: 0.9975 - val_loss: 0.2796 - val_accuracy: 0.9338\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 107/300\n",
      "469/469 - 1s - loss: 0.0229 - accuracy: 0.9974 - val_loss: 0.2795 - val_accuracy: 0.9339\n",
      "Epoch 108/300\n",
      "469/469 - 1s - loss: 0.0229 - accuracy: 0.9975 - val_loss: 0.2802 - val_accuracy: 0.9343\n",
      "Epoch 109/300\n",
      "469/469 - 1s - loss: 0.0229 - accuracy: 0.9975 - val_loss: 0.2797 - val_accuracy: 0.9340\n",
      "Epoch 110/300\n",
      "469/469 - 1s - loss: 0.0229 - accuracy: 0.9976 - val_loss: 0.2799 - val_accuracy: 0.9345\n",
      "Epoch 111/300\n",
      "469/469 - 1s - loss: 0.0229 - accuracy: 0.9974 - val_loss: 0.2798 - val_accuracy: 0.9338\n",
      "Epoch 112/300\n",
      "469/469 - 1s - loss: 0.0229 - accuracy: 0.9976 - val_loss: 0.2801 - val_accuracy: 0.9342\n",
      "Epoch 113/300\n",
      "469/469 - 1s - loss: 0.0229 - accuracy: 0.9975 - val_loss: 0.2802 - val_accuracy: 0.9341\n",
      "Epoch 114/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.2803 - val_accuracy: 0.9336\n",
      "Epoch 115/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.2804 - val_accuracy: 0.9347\n",
      "Epoch 116/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.2802 - val_accuracy: 0.9343\n",
      "Epoch 117/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.2802 - val_accuracy: 0.9339\n",
      "Epoch 118/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9974 - val_loss: 0.2804 - val_accuracy: 0.9346\n",
      "Epoch 119/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.2807 - val_accuracy: 0.9338\n",
      "Epoch 120/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.2803 - val_accuracy: 0.9339\n",
      "Epoch 121/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.2806 - val_accuracy: 0.9343\n",
      "Epoch 122/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9975 - val_loss: 0.2809 - val_accuracy: 0.9340\n",
      "Epoch 123/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.2805 - val_accuracy: 0.9340\n",
      "Epoch 124/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.2804 - val_accuracy: 0.9337\n",
      "Epoch 125/300\n",
      "469/469 - 1s - loss: 0.0228 - accuracy: 0.9976 - val_loss: 0.2806 - val_accuracy: 0.9338\n",
      "Epoch 126/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.2810 - val_accuracy: 0.9341\n",
      "Epoch 127/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.2807 - val_accuracy: 0.9338\n",
      "Epoch 128/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.2810 - val_accuracy: 0.9342\n",
      "Epoch 129/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9975 - val_loss: 0.2805 - val_accuracy: 0.9340\n",
      "Epoch 130/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9977 - val_loss: 0.2807 - val_accuracy: 0.9340\n",
      "Epoch 131/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.2812 - val_accuracy: 0.9338\n",
      "Epoch 132/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9976 - val_loss: 0.2809 - val_accuracy: 0.9338\n",
      "Epoch 133/300\n",
      "469/469 - 1s - loss: 0.0227 - accuracy: 0.9977 - val_loss: 0.2811 - val_accuracy: 0.9341\n",
      "Epoch 134/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9976 - val_loss: 0.2813 - val_accuracy: 0.9340\n",
      "Epoch 135/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9977 - val_loss: 0.2810 - val_accuracy: 0.9346\n",
      "Epoch 136/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9977 - val_loss: 0.2812 - val_accuracy: 0.9340\n",
      "Epoch 137/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9977 - val_loss: 0.2816 - val_accuracy: 0.9342\n",
      "Epoch 138/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9977 - val_loss: 0.2810 - val_accuracy: 0.9340\n",
      "Epoch 139/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9977 - val_loss: 0.2810 - val_accuracy: 0.9338\n",
      "Epoch 140/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9976 - val_loss: 0.2811 - val_accuracy: 0.9338\n",
      "Epoch 141/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9977 - val_loss: 0.2820 - val_accuracy: 0.9341\n",
      "Epoch 142/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9975 - val_loss: 0.2813 - val_accuracy: 0.9340\n",
      "Epoch 143/300\n",
      "469/469 - 1s - loss: 0.0226 - accuracy: 0.9976 - val_loss: 0.2814 - val_accuracy: 0.9340\n",
      "Epoch 144/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2815 - val_accuracy: 0.9339\n",
      "Epoch 145/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2815 - val_accuracy: 0.9341\n",
      "Epoch 146/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9976 - val_loss: 0.2816 - val_accuracy: 0.9341\n",
      "Epoch 147/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2815 - val_accuracy: 0.9340\n",
      "Epoch 148/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2817 - val_accuracy: 0.9338\n",
      "Epoch 149/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2818 - val_accuracy: 0.9341\n",
      "Epoch 150/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2818 - val_accuracy: 0.9341\n",
      "Epoch 151/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2821 - val_accuracy: 0.9341\n",
      "Epoch 152/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9976 - val_loss: 0.2819 - val_accuracy: 0.9342\n",
      "Epoch 153/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2818 - val_accuracy: 0.9339\n",
      "Epoch 154/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2819 - val_accuracy: 0.9341\n",
      "Epoch 155/300\n",
      "469/469 - 1s - loss: 0.0225 - accuracy: 0.9977 - val_loss: 0.2819 - val_accuracy: 0.9339\n",
      "Epoch 156/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2821 - val_accuracy: 0.9339\n",
      "Epoch 157/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2821 - val_accuracy: 0.9344\n",
      "Epoch 158/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2824 - val_accuracy: 0.9340\n",
      "Epoch 159/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2826 - val_accuracy: 0.9338\n",
      "Epoch 160/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2820 - val_accuracy: 0.9335\n",
      "Epoch 161/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2825 - val_accuracy: 0.9343\n",
      "Epoch 162/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9976 - val_loss: 0.2825 - val_accuracy: 0.9343\n",
      "Epoch 163/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2823 - val_accuracy: 0.9339\n",
      "Epoch 164/300\n",
      "469/469 - 1s - loss: 0.0224 - accuracy: 0.9977 - val_loss: 0.2825 - val_accuracy: 0.9342\n",
      "Epoch 165/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9977 - val_loss: 0.2825 - val_accuracy: 0.9338\n",
      "Epoch 166/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9978 - val_loss: 0.2826 - val_accuracy: 0.9338\n",
      "Epoch 167/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9977 - val_loss: 0.2824 - val_accuracy: 0.9339\n",
      "Epoch 168/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9977 - val_loss: 0.2825 - val_accuracy: 0.9339\n",
      "Epoch 169/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9977 - val_loss: 0.2828 - val_accuracy: 0.9341\n",
      "Epoch 170/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9977 - val_loss: 0.2826 - val_accuracy: 0.9344\n",
      "Epoch 171/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9979 - val_loss: 0.2828 - val_accuracy: 0.9337\n",
      "Epoch 172/300\n",
      "469/469 - 1s - loss: 0.0223 - accuracy: 0.9977 - val_loss: 0.2824 - val_accuracy: 0.9340\n",
      "Epoch 173/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9978 - val_loss: 0.2824 - val_accuracy: 0.9340\n",
      "Epoch 174/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9977 - val_loss: 0.2829 - val_accuracy: 0.9341\n",
      "Epoch 175/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9979 - val_loss: 0.2823 - val_accuracy: 0.9339\n",
      "Epoch 176/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9979 - val_loss: 0.2833 - val_accuracy: 0.9344\n",
      "Epoch 177/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9978 - val_loss: 0.2830 - val_accuracy: 0.9340\n",
      "Epoch 178/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9977 - val_loss: 0.2830 - val_accuracy: 0.9339\n",
      "Epoch 179/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9977 - val_loss: 0.2832 - val_accuracy: 0.9340\n",
      "Epoch 180/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9977 - val_loss: 0.2826 - val_accuracy: 0.9338\n",
      "Epoch 181/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9978 - val_loss: 0.2834 - val_accuracy: 0.9343\n",
      "Epoch 182/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9978 - val_loss: 0.2834 - val_accuracy: 0.9342\n",
      "Epoch 183/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9978 - val_loss: 0.2832 - val_accuracy: 0.9343\n",
      "Epoch 184/300\n",
      "469/469 - 1s - loss: 0.0222 - accuracy: 0.9977 - val_loss: 0.2832 - val_accuracy: 0.9337\n",
      "Epoch 185/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9977 - val_loss: 0.2831 - val_accuracy: 0.9339\n",
      "Epoch 186/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9979 - val_loss: 0.2831 - val_accuracy: 0.9339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 187/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9978 - val_loss: 0.2834 - val_accuracy: 0.9343\n",
      "Epoch 188/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9978 - val_loss: 0.2836 - val_accuracy: 0.9342\n",
      "Epoch 189/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9978 - val_loss: 0.2835 - val_accuracy: 0.9338\n",
      "Epoch 190/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9979 - val_loss: 0.2835 - val_accuracy: 0.9343\n",
      "Epoch 191/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9977 - val_loss: 0.2835 - val_accuracy: 0.9340\n",
      "Epoch 192/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9979 - val_loss: 0.2839 - val_accuracy: 0.9339\n",
      "Epoch 193/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9977 - val_loss: 0.2837 - val_accuracy: 0.9340\n",
      "Epoch 194/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9978 - val_loss: 0.2838 - val_accuracy: 0.9341\n",
      "Epoch 195/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9977 - val_loss: 0.2838 - val_accuracy: 0.9342\n",
      "Epoch 196/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9979 - val_loss: 0.2837 - val_accuracy: 0.9339\n",
      "Epoch 197/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9978 - val_loss: 0.2841 - val_accuracy: 0.9340\n",
      "Epoch 198/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9980 - val_loss: 0.2839 - val_accuracy: 0.9339\n",
      "Epoch 199/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9978 - val_loss: 0.2839 - val_accuracy: 0.9340\n",
      "Epoch 200/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9979 - val_loss: 0.2842 - val_accuracy: 0.9343\n",
      "Epoch 201/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9979 - val_loss: 0.2841 - val_accuracy: 0.9340\n",
      "Epoch 202/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9979 - val_loss: 0.2840 - val_accuracy: 0.9341\n",
      "Epoch 203/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9979 - val_loss: 0.2841 - val_accuracy: 0.9338\n",
      "Epoch 204/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.2840 - val_accuracy: 0.9340\n",
      "Epoch 205/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.2842 - val_accuracy: 0.9338\n",
      "Epoch 206/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9978 - val_loss: 0.2844 - val_accuracy: 0.9341\n",
      "Epoch 207/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.2841 - val_accuracy: 0.9340\n",
      "Epoch 208/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.2849 - val_accuracy: 0.9342\n",
      "Epoch 209/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9978 - val_loss: 0.2843 - val_accuracy: 0.9341\n",
      "Epoch 210/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9978 - val_loss: 0.2845 - val_accuracy: 0.9341\n",
      "Epoch 211/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.2845 - val_accuracy: 0.9339\n",
      "Epoch 212/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.2845 - val_accuracy: 0.9337\n",
      "Epoch 213/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9978 - val_loss: 0.2847 - val_accuracy: 0.9337\n",
      "Epoch 214/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.2849 - val_accuracy: 0.9338\n",
      "Epoch 215/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.2847 - val_accuracy: 0.9338\n",
      "Epoch 216/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.2845 - val_accuracy: 0.9341\n",
      "Epoch 217/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.2851 - val_accuracy: 0.9341\n",
      "Epoch 218/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.2847 - val_accuracy: 0.9333\n",
      "Epoch 219/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.2848 - val_accuracy: 0.9339\n",
      "Epoch 220/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.2846 - val_accuracy: 0.9341\n",
      "Epoch 221/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.2848 - val_accuracy: 0.9337\n",
      "Epoch 222/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.2848 - val_accuracy: 0.9339\n",
      "Epoch 223/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9979 - val_loss: 0.2853 - val_accuracy: 0.9340\n",
      "Epoch 224/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2854 - val_accuracy: 0.9341\n",
      "Epoch 225/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9980 - val_loss: 0.2851 - val_accuracy: 0.9339\n",
      "Epoch 226/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2854 - val_accuracy: 0.9339\n",
      "Epoch 227/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2848 - val_accuracy: 0.9337\n",
      "Epoch 228/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2851 - val_accuracy: 0.9341\n",
      "Epoch 229/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2853 - val_accuracy: 0.9342\n",
      "Epoch 230/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9979 - val_loss: 0.2852 - val_accuracy: 0.9336\n",
      "Epoch 231/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2854 - val_accuracy: 0.9337\n",
      "Epoch 232/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2854 - val_accuracy: 0.9339\n",
      "Epoch 233/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2854 - val_accuracy: 0.9338\n",
      "Epoch 234/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9980 - val_loss: 0.2855 - val_accuracy: 0.9338\n",
      "Epoch 235/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9980 - val_loss: 0.2854 - val_accuracy: 0.9341\n",
      "Epoch 236/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9979 - val_loss: 0.2856 - val_accuracy: 0.9339\n",
      "Epoch 237/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9979 - val_loss: 0.2857 - val_accuracy: 0.9338\n",
      "Epoch 238/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9979 - val_loss: 0.2858 - val_accuracy: 0.9339\n",
      "Epoch 239/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9981 - val_loss: 0.2856 - val_accuracy: 0.9332\n",
      "Epoch 240/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9980 - val_loss: 0.2862 - val_accuracy: 0.9340\n",
      "Epoch 241/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9981 - val_loss: 0.2856 - val_accuracy: 0.9340\n",
      "Epoch 242/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9980 - val_loss: 0.2858 - val_accuracy: 0.9341\n",
      "Epoch 243/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9980 - val_loss: 0.2860 - val_accuracy: 0.9337\n",
      "Epoch 244/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9981 - val_loss: 0.2858 - val_accuracy: 0.9337\n",
      "Epoch 245/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2861 - val_accuracy: 0.9340\n",
      "Epoch 246/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2860 - val_accuracy: 0.9336\n",
      "Epoch 247/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2860 - val_accuracy: 0.9340\n",
      "Epoch 248/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2864 - val_accuracy: 0.9338\n",
      "Epoch 249/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2864 - val_accuracy: 0.9337\n",
      "Epoch 250/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2863 - val_accuracy: 0.9339\n",
      "Epoch 251/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9981 - val_loss: 0.2864 - val_accuracy: 0.9339\n",
      "Epoch 252/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9981 - val_loss: 0.2861 - val_accuracy: 0.9334\n",
      "Epoch 253/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2866 - val_accuracy: 0.9338\n",
      "Epoch 254/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9980 - val_loss: 0.2866 - val_accuracy: 0.9341\n",
      "Epoch 255/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2864 - val_accuracy: 0.9340\n",
      "Epoch 256/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.2863 - val_accuracy: 0.9337\n",
      "Epoch 257/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.2865 - val_accuracy: 0.9338\n",
      "Epoch 258/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.2865 - val_accuracy: 0.9337\n",
      "Epoch 259/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9980 - val_loss: 0.2867 - val_accuracy: 0.9337\n",
      "Epoch 260/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.2866 - val_accuracy: 0.9338\n",
      "Epoch 261/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9980 - val_loss: 0.2871 - val_accuracy: 0.9341\n",
      "Epoch 262/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.2869 - val_accuracy: 0.9338\n",
      "Epoch 263/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9980 - val_loss: 0.2867 - val_accuracy: 0.9338\n",
      "Epoch 264/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.2865 - val_accuracy: 0.9335\n",
      "Epoch 265/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2870 - val_accuracy: 0.9339\n",
      "Epoch 266/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2872 - val_accuracy: 0.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2870 - val_accuracy: 0.9339\n",
      "Epoch 268/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.2867 - val_accuracy: 0.9338\n",
      "Epoch 269/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2872 - val_accuracy: 0.9340\n",
      "Epoch 270/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2873 - val_accuracy: 0.9340\n",
      "Epoch 271/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2874 - val_accuracy: 0.9342\n",
      "Epoch 272/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2876 - val_accuracy: 0.9343\n",
      "Epoch 273/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2872 - val_accuracy: 0.9339\n",
      "Epoch 274/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2874 - val_accuracy: 0.9336\n",
      "Epoch 275/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9981 - val_loss: 0.2872 - val_accuracy: 0.9337\n",
      "Epoch 276/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2870 - val_accuracy: 0.9339\n",
      "Epoch 277/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2874 - val_accuracy: 0.9338\n",
      "Epoch 278/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2872 - val_accuracy: 0.9338\n",
      "Epoch 279/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2872 - val_accuracy: 0.9337\n",
      "Epoch 280/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2878 - val_accuracy: 0.9339\n",
      "Epoch 281/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2875 - val_accuracy: 0.9339\n",
      "Epoch 282/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9982 - val_loss: 0.2874 - val_accuracy: 0.9336\n",
      "Epoch 283/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2875 - val_accuracy: 0.9336\n",
      "Epoch 284/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2879 - val_accuracy: 0.9342\n",
      "Epoch 285/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9980 - val_loss: 0.2877 - val_accuracy: 0.9339\n",
      "Epoch 286/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2881 - val_accuracy: 0.9338\n",
      "Epoch 287/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9981 - val_loss: 0.2878 - val_accuracy: 0.9336\n",
      "Epoch 288/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.2885 - val_accuracy: 0.9341\n",
      "Epoch 289/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9982 - val_loss: 0.2881 - val_accuracy: 0.9336\n",
      "Epoch 290/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.2883 - val_accuracy: 0.9337\n",
      "Epoch 291/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.2883 - val_accuracy: 0.9342\n",
      "Epoch 292/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.2888 - val_accuracy: 0.9344\n",
      "Epoch 293/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9982 - val_loss: 0.2881 - val_accuracy: 0.9338\n",
      "Epoch 294/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.2884 - val_accuracy: 0.9341\n",
      "Epoch 295/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9982 - val_loss: 0.2879 - val_accuracy: 0.9338\n",
      "Epoch 296/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9982 - val_loss: 0.2883 - val_accuracy: 0.9335\n",
      "Epoch 297/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.2883 - val_accuracy: 0.9340\n",
      "Epoch 298/300\n",
      "469/469 - 1s - loss: 0.0210 - accuracy: 0.9982 - val_loss: 0.2885 - val_accuracy: 0.9337\n",
      "Epoch 299/300\n",
      "469/469 - 1s - loss: 0.0210 - accuracy: 0.9981 - val_loss: 0.2885 - val_accuracy: 0.9337\n",
      "Epoch 300/300\n",
      "469/469 - 1s - loss: 0.0210 - accuracy: 0.9981 - val_loss: 0.2883 - val_accuracy: 0.9337\n",
      "Epoch 1/300\n",
      "469/469 - 1s - loss: 0.0221 - accuracy: 0.9976 - val_loss: 0.2885 - val_accuracy: 0.9330\n",
      "Epoch 2/300\n",
      "469/469 - 1s - loss: 0.0220 - accuracy: 0.9977 - val_loss: 0.2896 - val_accuracy: 0.9336\n",
      "Epoch 3/300\n",
      "469/469 - 1s - loss: 0.0219 - accuracy: 0.9979 - val_loss: 0.2904 - val_accuracy: 0.9336\n",
      "Epoch 4/300\n",
      "469/469 - 1s - loss: 0.0218 - accuracy: 0.9977 - val_loss: 0.2902 - val_accuracy: 0.9333\n",
      "Epoch 5/300\n",
      "469/469 - 1s - loss: 0.0217 - accuracy: 0.9979 - val_loss: 0.2926 - val_accuracy: 0.9335\n",
      "Epoch 6/300\n",
      "469/469 - 1s - loss: 0.0216 - accuracy: 0.9978 - val_loss: 0.2921 - val_accuracy: 0.9329\n",
      "Epoch 7/300\n",
      "469/469 - 1s - loss: 0.0215 - accuracy: 0.9980 - val_loss: 0.2919 - val_accuracy: 0.9331\n",
      "Epoch 8/300\n",
      "469/469 - 1s - loss: 0.0214 - accuracy: 0.9981 - val_loss: 0.2928 - val_accuracy: 0.9334\n",
      "Epoch 9/300\n",
      "469/469 - 1s - loss: 0.0213 - accuracy: 0.9980 - val_loss: 0.2932 - val_accuracy: 0.9328\n",
      "Epoch 10/300\n",
      "469/469 - 1s - loss: 0.0212 - accuracy: 0.9979 - val_loss: 0.2939 - val_accuracy: 0.9326\n",
      "Epoch 11/300\n",
      "469/469 - 1s - loss: 0.0211 - accuracy: 0.9981 - val_loss: 0.2934 - val_accuracy: 0.9331\n",
      "Epoch 12/300\n",
      "469/469 - 1s - loss: 0.0210 - accuracy: 0.9980 - val_loss: 0.2947 - val_accuracy: 0.9348\n",
      "Epoch 13/300\n",
      "469/469 - 1s - loss: 0.0210 - accuracy: 0.9981 - val_loss: 0.2966 - val_accuracy: 0.9336\n",
      "Epoch 14/300\n",
      "469/469 - 1s - loss: 0.0209 - accuracy: 0.9981 - val_loss: 0.2944 - val_accuracy: 0.9333\n",
      "Epoch 15/300\n",
      "469/469 - 1s - loss: 0.0207 - accuracy: 0.9981 - val_loss: 0.2956 - val_accuracy: 0.9329\n",
      "Epoch 16/300\n",
      "469/469 - 1s - loss: 0.0208 - accuracy: 0.9981 - val_loss: 0.2963 - val_accuracy: 0.9340\n",
      "Epoch 17/300\n",
      "469/469 - 1s - loss: 0.0206 - accuracy: 0.9981 - val_loss: 0.2974 - val_accuracy: 0.9332\n",
      "Epoch 18/300\n",
      "469/469 - 1s - loss: 0.0205 - accuracy: 0.9983 - val_loss: 0.2975 - val_accuracy: 0.9326\n",
      "Epoch 19/300\n",
      "469/469 - 1s - loss: 0.0204 - accuracy: 0.9981 - val_loss: 0.2973 - val_accuracy: 0.9326\n",
      "Epoch 20/300\n",
      "469/469 - 1s - loss: 0.0204 - accuracy: 0.9983 - val_loss: 0.2976 - val_accuracy: 0.9326\n",
      "Epoch 21/300\n",
      "469/469 - 1s - loss: 0.0203 - accuracy: 0.9981 - val_loss: 0.2984 - val_accuracy: 0.9328\n",
      "Epoch 22/300\n",
      "469/469 - 1s - loss: 0.0201 - accuracy: 0.9984 - val_loss: 0.3000 - val_accuracy: 0.9331\n",
      "Epoch 23/300\n",
      "469/469 - 1s - loss: 0.0201 - accuracy: 0.9984 - val_loss: 0.3005 - val_accuracy: 0.9330\n",
      "Epoch 24/300\n",
      "469/469 - 1s - loss: 0.0200 - accuracy: 0.9983 - val_loss: 0.2993 - val_accuracy: 0.9335\n",
      "Epoch 25/300\n",
      "469/469 - 1s - loss: 0.0200 - accuracy: 0.9984 - val_loss: 0.3006 - val_accuracy: 0.9329\n",
      "Epoch 26/300\n",
      "469/469 - 1s - loss: 0.0199 - accuracy: 0.9984 - val_loss: 0.3006 - val_accuracy: 0.9325\n",
      "Epoch 27/300\n",
      "469/469 - 1s - loss: 0.0198 - accuracy: 0.9984 - val_loss: 0.3010 - val_accuracy: 0.9332\n",
      "Epoch 28/300\n",
      "469/469 - 1s - loss: 0.0197 - accuracy: 0.9985 - val_loss: 0.3005 - val_accuracy: 0.9331\n",
      "Epoch 29/300\n",
      "469/469 - 1s - loss: 0.0196 - accuracy: 0.9984 - val_loss: 0.3026 - val_accuracy: 0.9326\n",
      "Epoch 30/300\n",
      "469/469 - 1s - loss: 0.0196 - accuracy: 0.9985 - val_loss: 0.3016 - val_accuracy: 0.9327\n",
      "Epoch 31/300\n",
      "469/469 - 1s - loss: 0.0195 - accuracy: 0.9984 - val_loss: 0.3034 - val_accuracy: 0.9324\n",
      "Epoch 32/300\n",
      "469/469 - 1s - loss: 0.0194 - accuracy: 0.9985 - val_loss: 0.3049 - val_accuracy: 0.9329\n",
      "Epoch 33/300\n",
      "469/469 - 1s - loss: 0.0194 - accuracy: 0.9984 - val_loss: 0.3051 - val_accuracy: 0.9325\n",
      "Epoch 34/300\n",
      "469/469 - 1s - loss: 0.0192 - accuracy: 0.9987 - val_loss: 0.3040 - val_accuracy: 0.9323\n",
      "Epoch 35/300\n",
      "469/469 - 1s - loss: 0.0191 - accuracy: 0.9984 - val_loss: 0.3051 - val_accuracy: 0.9333\n",
      "Epoch 36/300\n",
      "469/469 - 1s - loss: 0.0190 - accuracy: 0.9985 - val_loss: 0.3051 - val_accuracy: 0.9327\n",
      "Epoch 37/300\n",
      "469/469 - 1s - loss: 0.0190 - accuracy: 0.9984 - val_loss: 0.3052 - val_accuracy: 0.9329\n",
      "Epoch 38/300\n",
      "469/469 - 1s - loss: 0.0189 - accuracy: 0.9987 - val_loss: 0.3045 - val_accuracy: 0.9324\n",
      "Epoch 39/300\n",
      "469/469 - 1s - loss: 0.0189 - accuracy: 0.9987 - val_loss: 0.3065 - val_accuracy: 0.9325\n",
      "Epoch 40/300\n",
      "469/469 - 1s - loss: 0.0188 - accuracy: 0.9985 - val_loss: 0.3072 - val_accuracy: 0.9332\n",
      "Epoch 41/300\n",
      "469/469 - 1s - loss: 0.0187 - accuracy: 0.9987 - val_loss: 0.3082 - val_accuracy: 0.9329\n",
      "Epoch 42/300\n",
      "469/469 - 1s - loss: 0.0186 - accuracy: 0.9986 - val_loss: 0.3075 - val_accuracy: 0.9323\n",
      "Epoch 43/300\n",
      "469/469 - 1s - loss: 0.0186 - accuracy: 0.9987 - val_loss: 0.3092 - val_accuracy: 0.9321\n",
      "Epoch 44/300\n",
      "469/469 - 1s - loss: 0.0185 - accuracy: 0.9987 - val_loss: 0.3105 - val_accuracy: 0.9328\n",
      "Epoch 45/300\n",
      "469/469 - 1s - loss: 0.0184 - accuracy: 0.9986 - val_loss: 0.3098 - val_accuracy: 0.9321\n",
      "Epoch 46/300\n",
      "469/469 - 1s - loss: 0.0184 - accuracy: 0.9987 - val_loss: 0.3109 - val_accuracy: 0.9325\n",
      "Epoch 47/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469/469 - 1s - loss: 0.0183 - accuracy: 0.9986 - val_loss: 0.3104 - val_accuracy: 0.9329\n",
      "Epoch 48/300\n",
      "469/469 - 1s - loss: 0.0182 - accuracy: 0.9986 - val_loss: 0.3096 - val_accuracy: 0.9332\n",
      "Epoch 49/300\n",
      "469/469 - 1s - loss: 0.0181 - accuracy: 0.9987 - val_loss: 0.3111 - val_accuracy: 0.9326\n",
      "Epoch 50/300\n",
      "469/469 - 1s - loss: 0.0181 - accuracy: 0.9987 - val_loss: 0.3115 - val_accuracy: 0.9329\n",
      "Epoch 51/300\n",
      "469/469 - 1s - loss: 0.0180 - accuracy: 0.9988 - val_loss: 0.3116 - val_accuracy: 0.9319\n",
      "Epoch 52/300\n",
      "469/469 - 1s - loss: 0.0179 - accuracy: 0.9988 - val_loss: 0.3121 - val_accuracy: 0.9327\n",
      "Epoch 53/300\n",
      "469/469 - 1s - loss: 0.0178 - accuracy: 0.9989 - val_loss: 0.3134 - val_accuracy: 0.9325\n",
      "Epoch 54/300\n",
      "469/469 - 1s - loss: 0.0178 - accuracy: 0.9988 - val_loss: 0.3128 - val_accuracy: 0.9320\n",
      "Epoch 55/300\n",
      "469/469 - 1s - loss: 0.0177 - accuracy: 0.9987 - val_loss: 0.3135 - val_accuracy: 0.9331\n",
      "Epoch 56/300\n",
      "469/469 - 1s - loss: 0.0176 - accuracy: 0.9988 - val_loss: 0.3137 - val_accuracy: 0.9329\n",
      "Epoch 57/300\n",
      "469/469 - 1s - loss: 0.0175 - accuracy: 0.9990 - val_loss: 0.3142 - val_accuracy: 0.9319\n",
      "Epoch 58/300\n",
      "469/469 - 1s - loss: 0.0175 - accuracy: 0.9990 - val_loss: 0.3149 - val_accuracy: 0.9324\n",
      "Epoch 59/300\n",
      "469/469 - 1s - loss: 0.0174 - accuracy: 0.9987 - val_loss: 0.3157 - val_accuracy: 0.9323\n",
      "Epoch 60/300\n",
      "469/469 - 1s - loss: 0.0174 - accuracy: 0.9989 - val_loss: 0.3157 - val_accuracy: 0.9316\n",
      "Epoch 61/300\n",
      "469/469 - 1s - loss: 0.0173 - accuracy: 0.9989 - val_loss: 0.3158 - val_accuracy: 0.9332\n",
      "Epoch 62/300\n",
      "469/469 - 1s - loss: 0.0172 - accuracy: 0.9989 - val_loss: 0.3167 - val_accuracy: 0.9322\n",
      "Epoch 63/300\n",
      "469/469 - 1s - loss: 0.0171 - accuracy: 0.9989 - val_loss: 0.3168 - val_accuracy: 0.9328\n",
      "Epoch 64/300\n",
      "469/469 - 1s - loss: 0.0171 - accuracy: 0.9988 - val_loss: 0.3182 - val_accuracy: 0.9327\n",
      "Epoch 65/300\n",
      "469/469 - 1s - loss: 0.0170 - accuracy: 0.9990 - val_loss: 0.3190 - val_accuracy: 0.9327\n",
      "Epoch 66/300\n",
      "469/469 - 1s - loss: 0.0169 - accuracy: 0.9990 - val_loss: 0.3182 - val_accuracy: 0.9320\n",
      "Epoch 67/300\n",
      "469/469 - 1s - loss: 0.0168 - accuracy: 0.9989 - val_loss: 0.3192 - val_accuracy: 0.9324\n",
      "Epoch 68/300\n",
      "469/469 - 1s - loss: 0.0169 - accuracy: 0.9990 - val_loss: 0.3192 - val_accuracy: 0.9323\n",
      "Epoch 69/300\n",
      "469/469 - 1s - loss: 0.0167 - accuracy: 0.9992 - val_loss: 0.3198 - val_accuracy: 0.9326\n",
      "Epoch 70/300\n",
      "469/469 - 1s - loss: 0.0166 - accuracy: 0.9991 - val_loss: 0.3206 - val_accuracy: 0.9327\n",
      "Epoch 71/300\n",
      "469/469 - 1s - loss: 0.0166 - accuracy: 0.9990 - val_loss: 0.3226 - val_accuracy: 0.9323\n",
      "Epoch 72/300\n",
      "469/469 - 1s - loss: 0.0166 - accuracy: 0.9991 - val_loss: 0.3203 - val_accuracy: 0.9332\n",
      "Epoch 73/300\n",
      "469/469 - 1s - loss: 0.0165 - accuracy: 0.9991 - val_loss: 0.3219 - val_accuracy: 0.9315\n",
      "Epoch 74/300\n",
      "469/469 - 1s - loss: 0.0164 - accuracy: 0.9990 - val_loss: 0.3225 - val_accuracy: 0.9324\n",
      "Epoch 75/300\n",
      "469/469 - 1s - loss: 0.0164 - accuracy: 0.9991 - val_loss: 0.3224 - val_accuracy: 0.9320\n",
      "Epoch 76/300\n",
      "469/469 - 1s - loss: 0.0163 - accuracy: 0.9990 - val_loss: 0.3228 - val_accuracy: 0.9327\n",
      "Epoch 77/300\n",
      "469/469 - 1s - loss: 0.0163 - accuracy: 0.9992 - val_loss: 0.3235 - val_accuracy: 0.9320\n",
      "Epoch 78/300\n",
      "469/469 - 1s - loss: 0.0162 - accuracy: 0.9991 - val_loss: 0.3245 - val_accuracy: 0.9320\n",
      "Epoch 79/300\n",
      "469/469 - 1s - loss: 0.0162 - accuracy: 0.9991 - val_loss: 0.3242 - val_accuracy: 0.9321\n",
      "Epoch 80/300\n",
      "469/469 - 1s - loss: 0.0161 - accuracy: 0.9990 - val_loss: 0.3248 - val_accuracy: 0.9315\n",
      "Epoch 81/300\n",
      "469/469 - 1s - loss: 0.0160 - accuracy: 0.9991 - val_loss: 0.3252 - val_accuracy: 0.9319\n",
      "Epoch 82/300\n",
      "469/469 - 1s - loss: 0.0159 - accuracy: 0.9991 - val_loss: 0.3272 - val_accuracy: 0.9329\n",
      "Epoch 83/300\n",
      "469/469 - 1s - loss: 0.0159 - accuracy: 0.9992 - val_loss: 0.3260 - val_accuracy: 0.9326\n",
      "Epoch 84/300\n",
      "469/469 - 1s - loss: 0.0158 - accuracy: 0.9991 - val_loss: 0.3259 - val_accuracy: 0.9325\n",
      "Epoch 85/300\n",
      "469/469 - 1s - loss: 0.0158 - accuracy: 0.9992 - val_loss: 0.3276 - val_accuracy: 0.9324\n",
      "Epoch 86/300\n",
      "469/469 - 1s - loss: 0.0157 - accuracy: 0.9992 - val_loss: 0.3285 - val_accuracy: 0.9314\n",
      "Epoch 87/300\n",
      "469/469 - 1s - loss: 0.0156 - accuracy: 0.9993 - val_loss: 0.3286 - val_accuracy: 0.9319\n",
      "Epoch 88/300\n",
      "469/469 - 1s - loss: 0.0156 - accuracy: 0.9993 - val_loss: 0.3281 - val_accuracy: 0.9314\n",
      "Epoch 89/300\n",
      "469/469 - 1s - loss: 0.0155 - accuracy: 0.9993 - val_loss: 0.3284 - val_accuracy: 0.9313\n",
      "Epoch 90/300\n",
      "469/469 - 1s - loss: 0.0155 - accuracy: 0.9992 - val_loss: 0.3302 - val_accuracy: 0.9315\n",
      "Epoch 91/300\n",
      "469/469 - 1s - loss: 0.0154 - accuracy: 0.9993 - val_loss: 0.3303 - val_accuracy: 0.9322\n",
      "Epoch 92/300\n",
      "469/469 - 1s - loss: 0.0153 - accuracy: 0.9993 - val_loss: 0.3308 - val_accuracy: 0.9312\n",
      "Epoch 93/300\n",
      "469/469 - 1s - loss: 0.0153 - accuracy: 0.9993 - val_loss: 0.3305 - val_accuracy: 0.9324\n",
      "Epoch 94/300\n",
      "469/469 - 1s - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.3308 - val_accuracy: 0.9326\n",
      "Epoch 95/300\n",
      "469/469 - 1s - loss: 0.0152 - accuracy: 0.9993 - val_loss: 0.3316 - val_accuracy: 0.9320\n",
      "Epoch 96/300\n",
      "469/469 - 1s - loss: 0.0151 - accuracy: 0.9994 - val_loss: 0.3317 - val_accuracy: 0.9315\n",
      "Epoch 97/300\n",
      "469/469 - 1s - loss: 0.0151 - accuracy: 0.9993 - val_loss: 0.3324 - val_accuracy: 0.9322\n",
      "Epoch 98/300\n",
      "469/469 - 1s - loss: 0.0150 - accuracy: 0.9994 - val_loss: 0.3318 - val_accuracy: 0.9322\n",
      "Epoch 99/300\n",
      "469/469 - 1s - loss: 0.0149 - accuracy: 0.9993 - val_loss: 0.3334 - val_accuracy: 0.9319\n",
      "Epoch 100/300\n",
      "469/469 - 1s - loss: 0.0149 - accuracy: 0.9994 - val_loss: 0.3347 - val_accuracy: 0.9319\n",
      "Epoch 101/300\n",
      "469/469 - 1s - loss: 0.0148 - accuracy: 0.9995 - val_loss: 0.3338 - val_accuracy: 0.9320\n",
      "Epoch 102/300\n",
      "469/469 - 1s - loss: 0.0147 - accuracy: 0.9994 - val_loss: 0.3340 - val_accuracy: 0.9317\n",
      "Epoch 103/300\n",
      "469/469 - 1s - loss: 0.0147 - accuracy: 0.9995 - val_loss: 0.3350 - val_accuracy: 0.9316\n",
      "Epoch 104/300\n",
      "469/469 - 1s - loss: 0.0146 - accuracy: 0.9994 - val_loss: 0.3341 - val_accuracy: 0.9319\n",
      "Epoch 105/300\n",
      "469/469 - 1s - loss: 0.0147 - accuracy: 0.9993 - val_loss: 0.3355 - val_accuracy: 0.9318\n",
      "Epoch 106/300\n",
      "469/469 - 1s - loss: 0.0145 - accuracy: 0.9993 - val_loss: 0.3359 - val_accuracy: 0.9324\n",
      "Epoch 107/300\n",
      "469/469 - 1s - loss: 0.0145 - accuracy: 0.9995 - val_loss: 0.3359 - val_accuracy: 0.9320\n",
      "Epoch 108/300\n",
      "469/469 - 1s - loss: 0.0144 - accuracy: 0.9995 - val_loss: 0.3370 - val_accuracy: 0.9311\n",
      "Epoch 109/300\n",
      "469/469 - 1s - loss: 0.0144 - accuracy: 0.9995 - val_loss: 0.3380 - val_accuracy: 0.9325\n",
      "Epoch 110/300\n",
      "469/469 - 1s - loss: 0.0143 - accuracy: 0.9995 - val_loss: 0.3376 - val_accuracy: 0.9315\n",
      "Epoch 111/300\n",
      "469/469 - 1s - loss: 0.0143 - accuracy: 0.9994 - val_loss: 0.3382 - val_accuracy: 0.9311\n",
      "Epoch 112/300\n",
      "469/469 - 1s - loss: 0.0142 - accuracy: 0.9995 - val_loss: 0.3392 - val_accuracy: 0.9316\n",
      "Epoch 113/300\n",
      "469/469 - 1s - loss: 0.0142 - accuracy: 0.9995 - val_loss: 0.3402 - val_accuracy: 0.9310\n",
      "Epoch 114/300\n",
      "469/469 - 1s - loss: 0.0141 - accuracy: 0.9995 - val_loss: 0.3395 - val_accuracy: 0.9330\n",
      "Epoch 115/300\n",
      "469/469 - 1s - loss: 0.0141 - accuracy: 0.9995 - val_loss: 0.3409 - val_accuracy: 0.9313\n",
      "Epoch 116/300\n",
      "469/469 - 1s - loss: 0.0140 - accuracy: 0.9995 - val_loss: 0.3404 - val_accuracy: 0.9315\n",
      "Epoch 117/300\n",
      "469/469 - 1s - loss: 0.0140 - accuracy: 0.9995 - val_loss: 0.3400 - val_accuracy: 0.9312\n",
      "Epoch 118/300\n",
      "469/469 - 1s - loss: 0.0139 - accuracy: 0.9994 - val_loss: 0.3422 - val_accuracy: 0.9313\n",
      "Epoch 119/300\n",
      "469/469 - 1s - loss: 0.0139 - accuracy: 0.9995 - val_loss: 0.3426 - val_accuracy: 0.9310\n",
      "Epoch 120/300\n",
      "469/469 - 1s - loss: 0.0138 - accuracy: 0.9995 - val_loss: 0.3418 - val_accuracy: 0.9315\n",
      "Epoch 121/300\n",
      "469/469 - 1s - loss: 0.0137 - accuracy: 0.9997 - val_loss: 0.3424 - val_accuracy: 0.9308\n",
      "Epoch 122/300\n",
      "469/469 - 1s - loss: 0.0137 - accuracy: 0.9995 - val_loss: 0.3440 - val_accuracy: 0.9324\n",
      "Epoch 123/300\n",
      "469/469 - 1s - loss: 0.0136 - accuracy: 0.9996 - val_loss: 0.3446 - val_accuracy: 0.9314\n",
      "Epoch 124/300\n",
      "469/469 - 1s - loss: 0.0136 - accuracy: 0.9996 - val_loss: 0.3444 - val_accuracy: 0.9312\n",
      "Epoch 125/300\n",
      "469/469 - 1s - loss: 0.0136 - accuracy: 0.9996 - val_loss: 0.3449 - val_accuracy: 0.9308\n",
      "Epoch 126/300\n",
      "469/469 - 1s - loss: 0.0135 - accuracy: 0.9996 - val_loss: 0.3445 - val_accuracy: 0.9317\n",
      "Epoch 127/300\n",
      "469/469 - 1s - loss: 0.0134 - accuracy: 0.9995 - val_loss: 0.3450 - val_accuracy: 0.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 128/300\n",
      "469/469 - 1s - loss: 0.0134 - accuracy: 0.9995 - val_loss: 0.3470 - val_accuracy: 0.9316\n",
      "Epoch 129/300\n",
      "469/469 - 1s - loss: 0.0134 - accuracy: 0.9996 - val_loss: 0.3462 - val_accuracy: 0.9314\n",
      "Epoch 130/300\n",
      "469/469 - 1s - loss: 0.0133 - accuracy: 0.9996 - val_loss: 0.3475 - val_accuracy: 0.9312\n",
      "Epoch 131/300\n",
      "469/469 - 1s - loss: 0.0132 - accuracy: 0.9996 - val_loss: 0.3493 - val_accuracy: 0.9313\n",
      "Epoch 132/300\n",
      "469/469 - 1s - loss: 0.0132 - accuracy: 0.9996 - val_loss: 0.3484 - val_accuracy: 0.9314\n",
      "Epoch 133/300\n",
      "469/469 - 1s - loss: 0.0132 - accuracy: 0.9996 - val_loss: 0.3493 - val_accuracy: 0.9316\n",
      "Epoch 134/300\n",
      "469/469 - 1s - loss: 0.0131 - accuracy: 0.9995 - val_loss: 0.3497 - val_accuracy: 0.9312\n",
      "Epoch 135/300\n",
      "469/469 - 1s - loss: 0.0130 - accuracy: 0.9996 - val_loss: 0.3497 - val_accuracy: 0.9316\n",
      "Epoch 136/300\n",
      "469/469 - 1s - loss: 0.0130 - accuracy: 0.9996 - val_loss: 0.3506 - val_accuracy: 0.9314\n",
      "Epoch 137/300\n",
      "469/469 - 1s - loss: 0.0130 - accuracy: 0.9996 - val_loss: 0.3497 - val_accuracy: 0.9320\n",
      "Epoch 138/300\n",
      "469/469 - 1s - loss: 0.0129 - accuracy: 0.9996 - val_loss: 0.3503 - val_accuracy: 0.9315\n",
      "Epoch 139/300\n",
      "469/469 - 1s - loss: 0.0128 - accuracy: 0.9997 - val_loss: 0.3512 - val_accuracy: 0.9313\n",
      "Epoch 140/300\n",
      "469/469 - 1s - loss: 0.0128 - accuracy: 0.9997 - val_loss: 0.3517 - val_accuracy: 0.9312\n",
      "Epoch 141/300\n",
      "469/469 - 1s - loss: 0.0128 - accuracy: 0.9997 - val_loss: 0.3529 - val_accuracy: 0.9315\n",
      "Epoch 142/300\n",
      "469/469 - 1s - loss: 0.0127 - accuracy: 0.9996 - val_loss: 0.3522 - val_accuracy: 0.9317\n",
      "Epoch 143/300\n",
      "469/469 - 1s - loss: 0.0127 - accuracy: 0.9996 - val_loss: 0.3527 - val_accuracy: 0.9316\n",
      "Epoch 144/300\n",
      "469/469 - 1s - loss: 0.0126 - accuracy: 0.9997 - val_loss: 0.3535 - val_accuracy: 0.9319\n",
      "Epoch 145/300\n",
      "469/469 - 1s - loss: 0.0126 - accuracy: 0.9996 - val_loss: 0.3540 - val_accuracy: 0.9310\n",
      "Epoch 146/300\n",
      "469/469 - 1s - loss: 0.0125 - accuracy: 0.9997 - val_loss: 0.3538 - val_accuracy: 0.9313\n",
      "Epoch 147/300\n",
      "469/469 - 1s - loss: 0.0125 - accuracy: 0.9996 - val_loss: 0.3553 - val_accuracy: 0.9313\n",
      "Epoch 148/300\n",
      "469/469 - 1s - loss: 0.0125 - accuracy: 0.9997 - val_loss: 0.3556 - val_accuracy: 0.9319\n",
      "Epoch 149/300\n",
      "469/469 - 1s - loss: 0.0124 - accuracy: 0.9997 - val_loss: 0.3570 - val_accuracy: 0.9311\n",
      "Epoch 150/300\n",
      "469/469 - 1s - loss: 0.0124 - accuracy: 0.9997 - val_loss: 0.3565 - val_accuracy: 0.9309\n",
      "Epoch 151/300\n",
      "469/469 - 1s - loss: 0.0123 - accuracy: 0.9996 - val_loss: 0.3579 - val_accuracy: 0.9315\n",
      "Epoch 152/300\n",
      "469/469 - 1s - loss: 0.0123 - accuracy: 0.9997 - val_loss: 0.3575 - val_accuracy: 0.9311\n",
      "Epoch 153/300\n",
      "469/469 - 1s - loss: 0.0122 - accuracy: 0.9997 - val_loss: 0.3574 - val_accuracy: 0.9317\n",
      "Epoch 154/300\n",
      "469/469 - 1s - loss: 0.0122 - accuracy: 0.9997 - val_loss: 0.3575 - val_accuracy: 0.9313\n",
      "Epoch 155/300\n",
      "469/469 - 1s - loss: 0.0122 - accuracy: 0.9997 - val_loss: 0.3591 - val_accuracy: 0.9310\n",
      "Epoch 156/300\n",
      "469/469 - 1s - loss: 0.0121 - accuracy: 0.9997 - val_loss: 0.3589 - val_accuracy: 0.9314\n",
      "Epoch 157/300\n",
      "469/469 - 1s - loss: 0.0120 - accuracy: 0.9997 - val_loss: 0.3595 - val_accuracy: 0.9316\n",
      "Epoch 158/300\n",
      "469/469 - 1s - loss: 0.0120 - accuracy: 0.9997 - val_loss: 0.3610 - val_accuracy: 0.9318\n",
      "Epoch 159/300\n",
      "469/469 - 1s - loss: 0.0120 - accuracy: 0.9997 - val_loss: 0.3623 - val_accuracy: 0.9312\n",
      "Epoch 160/300\n",
      "469/469 - 1s - loss: 0.0119 - accuracy: 0.9997 - val_loss: 0.3605 - val_accuracy: 0.9313\n",
      "Epoch 161/300\n",
      "469/469 - 1s - loss: 0.0118 - accuracy: 0.9997 - val_loss: 0.3617 - val_accuracy: 0.9308\n",
      "Epoch 162/300\n",
      "469/469 - 1s - loss: 0.0119 - accuracy: 0.9997 - val_loss: 0.3630 - val_accuracy: 0.9310\n",
      "Epoch 163/300\n",
      "469/469 - 1s - loss: 0.0118 - accuracy: 0.9997 - val_loss: 0.3625 - val_accuracy: 0.9310\n",
      "Epoch 164/300\n",
      "469/469 - 1s - loss: 0.0117 - accuracy: 0.9998 - val_loss: 0.3620 - val_accuracy: 0.9320\n",
      "Epoch 165/300\n",
      "469/469 - 1s - loss: 0.0117 - accuracy: 0.9998 - val_loss: 0.3626 - val_accuracy: 0.9313\n",
      "Epoch 166/300\n",
      "469/469 - 1s - loss: 0.0117 - accuracy: 0.9997 - val_loss: 0.3641 - val_accuracy: 0.9317\n",
      "Epoch 167/300\n",
      "469/469 - 1s - loss: 0.0116 - accuracy: 0.9998 - val_loss: 0.3637 - val_accuracy: 0.9311\n",
      "Epoch 168/300\n",
      "469/469 - 1s - loss: 0.0116 - accuracy: 0.9997 - val_loss: 0.3647 - val_accuracy: 0.9309\n",
      "Epoch 169/300\n",
      "469/469 - 1s - loss: 0.0115 - accuracy: 0.9998 - val_loss: 0.3650 - val_accuracy: 0.9311\n",
      "Epoch 170/300\n",
      "469/469 - 1s - loss: 0.0115 - accuracy: 0.9998 - val_loss: 0.3665 - val_accuracy: 0.9310\n",
      "Epoch 171/300\n",
      "469/469 - 1s - loss: 0.0115 - accuracy: 0.9998 - val_loss: 0.3669 - val_accuracy: 0.9306\n",
      "Epoch 172/300\n",
      "469/469 - 1s - loss: 0.0114 - accuracy: 0.9997 - val_loss: 0.3660 - val_accuracy: 0.9307\n",
      "Epoch 173/300\n",
      "469/469 - 1s - loss: 0.0113 - accuracy: 0.9997 - val_loss: 0.3664 - val_accuracy: 0.9312\n",
      "Epoch 174/300\n",
      "469/469 - 1s - loss: 0.0113 - accuracy: 0.9998 - val_loss: 0.3663 - val_accuracy: 0.9311\n",
      "Epoch 175/300\n",
      "469/469 - 1s - loss: 0.0113 - accuracy: 0.9997 - val_loss: 0.3680 - val_accuracy: 0.9303\n",
      "Epoch 176/300\n",
      "469/469 - 1s - loss: 0.0113 - accuracy: 0.9997 - val_loss: 0.3687 - val_accuracy: 0.9304\n",
      "Epoch 177/300\n",
      "469/469 - 1s - loss: 0.0112 - accuracy: 0.9998 - val_loss: 0.3691 - val_accuracy: 0.9320\n",
      "Epoch 178/300\n",
      "469/469 - 1s - loss: 0.0111 - accuracy: 0.9998 - val_loss: 0.3689 - val_accuracy: 0.9307\n",
      "Epoch 179/300\n",
      "469/469 - 1s - loss: 0.0111 - accuracy: 0.9997 - val_loss: 0.3688 - val_accuracy: 0.9301\n",
      "Epoch 180/300\n",
      "469/469 - 1s - loss: 0.0111 - accuracy: 0.9998 - val_loss: 0.3703 - val_accuracy: 0.9311\n",
      "Epoch 181/300\n",
      "469/469 - 1s - loss: 0.0111 - accuracy: 0.9998 - val_loss: 0.3711 - val_accuracy: 0.9312\n",
      "Epoch 182/300\n",
      "469/469 - 1s - loss: 0.0110 - accuracy: 0.9998 - val_loss: 0.3709 - val_accuracy: 0.9306\n",
      "Epoch 183/300\n",
      "469/469 - 1s - loss: 0.0109 - accuracy: 0.9998 - val_loss: 0.3723 - val_accuracy: 0.9304\n",
      "Epoch 184/300\n",
      "469/469 - 1s - loss: 0.0109 - accuracy: 0.9998 - val_loss: 0.3716 - val_accuracy: 0.9308\n",
      "Epoch 185/300\n",
      "469/469 - 1s - loss: 0.0108 - accuracy: 0.9998 - val_loss: 0.3725 - val_accuracy: 0.9307\n",
      "Epoch 186/300\n",
      "469/469 - 1s - loss: 0.0108 - accuracy: 0.9998 - val_loss: 0.3719 - val_accuracy: 0.9303\n",
      "Epoch 187/300\n",
      "469/469 - 1s - loss: 0.0108 - accuracy: 0.9998 - val_loss: 0.3722 - val_accuracy: 0.9310\n",
      "Epoch 188/300\n",
      "469/469 - 1s - loss: 0.0108 - accuracy: 0.9998 - val_loss: 0.3731 - val_accuracy: 0.9305\n",
      "Epoch 189/300\n",
      "469/469 - 1s - loss: 0.0107 - accuracy: 0.9998 - val_loss: 0.3742 - val_accuracy: 0.9301\n",
      "Epoch 190/300\n",
      "469/469 - 1s - loss: 0.0107 - accuracy: 0.9998 - val_loss: 0.3741 - val_accuracy: 0.9310\n",
      "Epoch 191/300\n",
      "469/469 - 1s - loss: 0.0107 - accuracy: 0.9998 - val_loss: 0.3744 - val_accuracy: 0.9307\n",
      "Epoch 192/300\n",
      "469/469 - 1s - loss: 0.0106 - accuracy: 0.9998 - val_loss: 0.3758 - val_accuracy: 0.9299\n",
      "Epoch 193/300\n",
      "469/469 - 1s - loss: 0.0105 - accuracy: 0.9998 - val_loss: 0.3745 - val_accuracy: 0.9311\n",
      "Epoch 194/300\n",
      "469/469 - 1s - loss: 0.0106 - accuracy: 0.9998 - val_loss: 0.3762 - val_accuracy: 0.9308\n",
      "Epoch 195/300\n",
      "469/469 - 1s - loss: 0.0105 - accuracy: 0.9998 - val_loss: 0.3764 - val_accuracy: 0.9307\n",
      "Epoch 196/300\n",
      "469/469 - 1s - loss: 0.0104 - accuracy: 0.9998 - val_loss: 0.3763 - val_accuracy: 0.9310\n",
      "Epoch 197/300\n",
      "469/469 - 1s - loss: 0.0104 - accuracy: 0.9999 - val_loss: 0.3784 - val_accuracy: 0.9308\n",
      "Epoch 198/300\n",
      "469/469 - 1s - loss: 0.0104 - accuracy: 0.9998 - val_loss: 0.3779 - val_accuracy: 0.9310\n",
      "Epoch 199/300\n",
      "469/469 - 1s - loss: 0.0103 - accuracy: 0.9998 - val_loss: 0.3779 - val_accuracy: 0.9305\n",
      "Epoch 200/300\n",
      "469/469 - 1s - loss: 0.0103 - accuracy: 0.9999 - val_loss: 0.3792 - val_accuracy: 0.9298\n",
      "Epoch 201/300\n",
      "469/469 - 1s - loss: 0.0103 - accuracy: 0.9998 - val_loss: 0.3795 - val_accuracy: 0.9307\n",
      "Epoch 202/300\n",
      "469/469 - 1s - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.3802 - val_accuracy: 0.9305\n",
      "Epoch 203/300\n",
      "469/469 - 1s - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.3809 - val_accuracy: 0.9308\n",
      "Epoch 204/300\n",
      "469/469 - 1s - loss: 0.0101 - accuracy: 0.9999 - val_loss: 0.3808 - val_accuracy: 0.9304\n",
      "Epoch 205/300\n",
      "469/469 - 1s - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.3807 - val_accuracy: 0.9309\n",
      "Epoch 206/300\n",
      "469/469 - 1s - loss: 0.0101 - accuracy: 0.9998 - val_loss: 0.3820 - val_accuracy: 0.9302\n",
      "Epoch 207/300\n",
      "469/469 - 1s - loss: 0.0100 - accuracy: 0.9998 - val_loss: 0.3821 - val_accuracy: 0.9303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/300\n",
      "469/469 - 1s - loss: 0.0100 - accuracy: 0.9999 - val_loss: 0.3834 - val_accuracy: 0.9305\n",
      "Epoch 209/300\n",
      "469/469 - 1s - loss: 0.0100 - accuracy: 0.9998 - val_loss: 0.3833 - val_accuracy: 0.9305\n",
      "Epoch 210/300\n",
      "469/469 - 1s - loss: 0.0099 - accuracy: 0.9999 - val_loss: 0.3841 - val_accuracy: 0.9303\n",
      "Epoch 211/300\n",
      "469/469 - 1s - loss: 0.0099 - accuracy: 0.9999 - val_loss: 0.3850 - val_accuracy: 0.9302\n",
      "Epoch 212/300\n",
      "469/469 - 1s - loss: 0.0099 - accuracy: 0.9998 - val_loss: 0.3835 - val_accuracy: 0.9301\n",
      "Epoch 213/300\n",
      "469/469 - 1s - loss: 0.0098 - accuracy: 0.9998 - val_loss: 0.3852 - val_accuracy: 0.9309\n",
      "Epoch 214/300\n",
      "469/469 - 1s - loss: 0.0098 - accuracy: 0.9998 - val_loss: 0.3861 - val_accuracy: 0.9300\n",
      "Epoch 215/300\n",
      "469/469 - 1s - loss: 0.0098 - accuracy: 0.9999 - val_loss: 0.3854 - val_accuracy: 0.9300\n",
      "Epoch 216/300\n",
      "469/469 - 1s - loss: 0.0097 - accuracy: 0.9998 - val_loss: 0.3862 - val_accuracy: 0.9307\n",
      "Epoch 217/300\n",
      "469/469 - 1s - loss: 0.0097 - accuracy: 0.9998 - val_loss: 0.3877 - val_accuracy: 0.9308\n",
      "Epoch 218/300\n",
      "469/469 - 1s - loss: 0.0096 - accuracy: 0.9999 - val_loss: 0.3865 - val_accuracy: 0.9298\n",
      "Epoch 219/300\n",
      "469/469 - 1s - loss: 0.0097 - accuracy: 0.9999 - val_loss: 0.3875 - val_accuracy: 0.9300\n",
      "Epoch 220/300\n",
      "469/469 - 1s - loss: 0.0096 - accuracy: 0.9998 - val_loss: 0.3883 - val_accuracy: 0.9302\n",
      "Epoch 221/300\n",
      "469/469 - 1s - loss: 0.0096 - accuracy: 0.9999 - val_loss: 0.3894 - val_accuracy: 0.9303\n",
      "Epoch 222/300\n",
      "469/469 - 1s - loss: 0.0095 - accuracy: 0.9999 - val_loss: 0.3901 - val_accuracy: 0.9305\n",
      "Epoch 223/300\n",
      "469/469 - 1s - loss: 0.0095 - accuracy: 0.9999 - val_loss: 0.3900 - val_accuracy: 0.9300\n",
      "Epoch 224/300\n",
      "469/469 - 1s - loss: 0.0095 - accuracy: 0.9999 - val_loss: 0.3910 - val_accuracy: 0.9307\n",
      "Epoch 225/300\n",
      "469/469 - 1s - loss: 0.0094 - accuracy: 0.9999 - val_loss: 0.3904 - val_accuracy: 0.9307\n",
      "Epoch 226/300\n",
      "469/469 - 1s - loss: 0.0094 - accuracy: 0.9998 - val_loss: 0.3911 - val_accuracy: 0.9305\n",
      "Epoch 227/300\n",
      "469/469 - 1s - loss: 0.0094 - accuracy: 0.9999 - val_loss: 0.3923 - val_accuracy: 0.9300\n",
      "Epoch 228/300\n",
      "469/469 - 1s - loss: 0.0093 - accuracy: 0.9999 - val_loss: 0.3914 - val_accuracy: 0.9297\n",
      "Epoch 229/300\n",
      "469/469 - 1s - loss: 0.0093 - accuracy: 0.9999 - val_loss: 0.3928 - val_accuracy: 0.9302\n",
      "Epoch 230/300\n",
      "469/469 - 1s - loss: 0.0092 - accuracy: 0.9999 - val_loss: 0.3927 - val_accuracy: 0.9307\n",
      "Epoch 231/300\n",
      "469/469 - 1s - loss: 0.0092 - accuracy: 0.9999 - val_loss: 0.3938 - val_accuracy: 0.9304\n",
      "Epoch 232/300\n",
      "469/469 - 1s - loss: 0.0092 - accuracy: 0.9999 - val_loss: 0.3941 - val_accuracy: 0.9301\n",
      "Epoch 233/300\n",
      "469/469 - 1s - loss: 0.0091 - accuracy: 0.9999 - val_loss: 0.3953 - val_accuracy: 0.9302\n",
      "Epoch 234/300\n",
      "469/469 - 1s - loss: 0.0092 - accuracy: 0.9999 - val_loss: 0.3947 - val_accuracy: 0.9303\n",
      "Epoch 235/300\n",
      "469/469 - 1s - loss: 0.0091 - accuracy: 0.9999 - val_loss: 0.3943 - val_accuracy: 0.9307\n",
      "Epoch 236/300\n",
      "469/469 - 1s - loss: 0.0091 - accuracy: 0.9999 - val_loss: 0.3956 - val_accuracy: 0.9297\n",
      "Epoch 237/300\n",
      "469/469 - 1s - loss: 0.0090 - accuracy: 0.9999 - val_loss: 0.3959 - val_accuracy: 0.9304\n",
      "Epoch 238/300\n",
      "469/469 - 1s - loss: 0.0090 - accuracy: 0.9999 - val_loss: 0.3967 - val_accuracy: 0.9301\n",
      "Epoch 239/300\n",
      "469/469 - 1s - loss: 0.0090 - accuracy: 0.9999 - val_loss: 0.3966 - val_accuracy: 0.9302\n",
      "Epoch 240/300\n",
      "469/469 - 1s - loss: 0.0089 - accuracy: 0.9999 - val_loss: 0.3978 - val_accuracy: 0.9303\n",
      "Epoch 241/300\n",
      "469/469 - 1s - loss: 0.0089 - accuracy: 0.9999 - val_loss: 0.3978 - val_accuracy: 0.9301\n",
      "Epoch 242/300\n",
      "469/469 - 1s - loss: 0.0089 - accuracy: 0.9999 - val_loss: 0.3992 - val_accuracy: 0.9306\n",
      "Epoch 243/300\n",
      "469/469 - 1s - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9300\n",
      "Epoch 244/300\n",
      "469/469 - 1s - loss: 0.0088 - accuracy: 0.9999 - val_loss: 0.3987 - val_accuracy: 0.9296\n",
      "Epoch 245/300\n",
      "469/469 - 1s - loss: 0.0087 - accuracy: 0.9999 - val_loss: 0.3992 - val_accuracy: 0.9297\n",
      "Epoch 246/300\n",
      "469/469 - 1s - loss: 0.0087 - accuracy: 0.9999 - val_loss: 0.4009 - val_accuracy: 0.9298\n",
      "Epoch 247/300\n",
      "469/469 - 1s - loss: 0.0087 - accuracy: 0.9999 - val_loss: 0.3997 - val_accuracy: 0.9296\n",
      "Epoch 248/300\n",
      "469/469 - 1s - loss: 0.0087 - accuracy: 0.9999 - val_loss: 0.4019 - val_accuracy: 0.9302\n",
      "Epoch 249/300\n",
      "469/469 - 1s - loss: 0.0087 - accuracy: 0.9999 - val_loss: 0.4014 - val_accuracy: 0.9295\n",
      "Epoch 250/300\n",
      "469/469 - 1s - loss: 0.0086 - accuracy: 0.9999 - val_loss: 0.4021 - val_accuracy: 0.9301\n",
      "Epoch 251/300\n",
      "469/469 - 1s - loss: 0.0086 - accuracy: 0.9999 - val_loss: 0.4029 - val_accuracy: 0.9296\n",
      "Epoch 252/300\n",
      "469/469 - 1s - loss: 0.0086 - accuracy: 0.9999 - val_loss: 0.4020 - val_accuracy: 0.9304\n",
      "Epoch 253/300\n",
      "469/469 - 1s - loss: 0.0086 - accuracy: 0.9999 - val_loss: 0.4044 - val_accuracy: 0.9294\n",
      "Epoch 254/300\n",
      "469/469 - 1s - loss: 0.0085 - accuracy: 0.9999 - val_loss: 0.4039 - val_accuracy: 0.9291\n",
      "Epoch 255/300\n",
      "469/469 - 1s - loss: 0.0085 - accuracy: 0.9999 - val_loss: 0.4029 - val_accuracy: 0.9301\n",
      "Epoch 256/300\n",
      "469/469 - 1s - loss: 0.0084 - accuracy: 0.9999 - val_loss: 0.4039 - val_accuracy: 0.9303\n",
      "Epoch 257/300\n",
      "469/469 - 1s - loss: 0.0084 - accuracy: 0.9999 - val_loss: 0.4046 - val_accuracy: 0.9298\n",
      "Epoch 258/300\n",
      "469/469 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9304\n",
      "Epoch 259/300\n",
      "469/469 - 1s - loss: 0.0084 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9296\n",
      "Epoch 260/300\n",
      "469/469 - 1s - loss: 0.0084 - accuracy: 0.9999 - val_loss: 0.4072 - val_accuracy: 0.9297\n",
      "Epoch 261/300\n",
      "469/469 - 1s - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9294\n",
      "Epoch 262/300\n",
      "469/469 - 1s - loss: 0.0083 - accuracy: 0.9999 - val_loss: 0.4079 - val_accuracy: 0.9302\n",
      "Epoch 263/300\n",
      "469/469 - 1s - loss: 0.0082 - accuracy: 0.9999 - val_loss: 0.4081 - val_accuracy: 0.9295\n",
      "Epoch 264/300\n",
      "469/469 - 1s - loss: 0.0082 - accuracy: 0.9999 - val_loss: 0.4078 - val_accuracy: 0.9300\n",
      "Epoch 265/300\n",
      "469/469 - 1s - loss: 0.0082 - accuracy: 0.9999 - val_loss: 0.4081 - val_accuracy: 0.9299\n",
      "Epoch 266/300\n",
      "469/469 - 1s - loss: 0.0082 - accuracy: 0.9999 - val_loss: 0.4098 - val_accuracy: 0.9301\n",
      "Epoch 267/300\n",
      "469/469 - 1s - loss: 0.0081 - accuracy: 0.9999 - val_loss: 0.4105 - val_accuracy: 0.9295\n",
      "Epoch 268/300\n",
      "469/469 - 1s - loss: 0.0081 - accuracy: 0.9999 - val_loss: 0.4096 - val_accuracy: 0.9298\n",
      "Epoch 269/300\n",
      "469/469 - 1s - loss: 0.0081 - accuracy: 0.9999 - val_loss: 0.4112 - val_accuracy: 0.9296\n",
      "Epoch 270/300\n",
      "469/469 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9294\n",
      "Epoch 271/300\n",
      "469/469 - 1s - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9294\n",
      "Epoch 272/300\n",
      "469/469 - 1s - loss: 0.0080 - accuracy: 0.9999 - val_loss: 0.4131 - val_accuracy: 0.9295\n",
      "Epoch 273/300\n",
      "469/469 - 1s - loss: 0.0080 - accuracy: 0.9999 - val_loss: 0.4122 - val_accuracy: 0.9299\n",
      "Epoch 274/300\n",
      "469/469 - 1s - loss: 0.0079 - accuracy: 0.9999 - val_loss: 0.4133 - val_accuracy: 0.9296\n",
      "Epoch 275/300\n",
      "469/469 - 1s - loss: 0.0079 - accuracy: 0.9999 - val_loss: 0.4136 - val_accuracy: 0.9303\n",
      "Epoch 276/300\n",
      "469/469 - 1s - loss: 0.0079 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9295\n",
      "Epoch 277/300\n",
      "469/469 - 1s - loss: 0.0079 - accuracy: 0.9999 - val_loss: 0.4145 - val_accuracy: 0.9300\n",
      "Epoch 278/300\n",
      "469/469 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9296\n",
      "Epoch 279/300\n",
      "469/469 - 1s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.9293\n",
      "Epoch 280/300\n",
      "469/469 - 1s - loss: 0.0078 - accuracy: 0.9999 - val_loss: 0.4155 - val_accuracy: 0.9297\n",
      "Epoch 281/300\n",
      "469/469 - 1s - loss: 0.0077 - accuracy: 0.9999 - val_loss: 0.4165 - val_accuracy: 0.9294\n",
      "Epoch 282/300\n",
      "469/469 - 1s - loss: 0.0077 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9295\n",
      "Epoch 283/300\n",
      "469/469 - 1s - loss: 0.0077 - accuracy: 0.9999 - val_loss: 0.4174 - val_accuracy: 0.9300\n",
      "Epoch 284/300\n",
      "469/469 - 1s - loss: 0.0076 - accuracy: 0.9999 - val_loss: 0.4173 - val_accuracy: 0.9301\n",
      "Epoch 285/300\n",
      "469/469 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9300\n",
      "Epoch 286/300\n",
      "469/469 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9288\n",
      "Epoch 287/300\n",
      "469/469 - 1s - loss: 0.0076 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/300\n",
      "469/469 - 1s - loss: 0.0076 - accuracy: 0.9999 - val_loss: 0.4196 - val_accuracy: 0.9291\n",
      "Epoch 289/300\n",
      "469/469 - 1s - loss: 0.0075 - accuracy: 0.9999 - val_loss: 0.4198 - val_accuracy: 0.9291\n",
      "Epoch 290/300\n",
      "469/469 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9297\n",
      "Epoch 291/300\n",
      "469/469 - 1s - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9294\n",
      "Epoch 292/300\n",
      "469/469 - 1s - loss: 0.0074 - accuracy: 0.9999 - val_loss: 0.4218 - val_accuracy: 0.9292\n",
      "Epoch 293/300\n",
      "469/469 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9288\n",
      "Epoch 294/300\n",
      "469/469 - 1s - loss: 0.0074 - accuracy: 0.9999 - val_loss: 0.4225 - val_accuracy: 0.9291\n",
      "Epoch 295/300\n",
      "469/469 - 1s - loss: 0.0074 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9299\n",
      "Epoch 296/300\n",
      "469/469 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9297\n",
      "Epoch 297/300\n",
      "469/469 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9292\n",
      "Epoch 298/300\n",
      "469/469 - 1s - loss: 0.0073 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9290\n",
      "Epoch 299/300\n",
      "469/469 - 1s - loss: 0.0073 - accuracy: 0.9999 - val_loss: 0.4249 - val_accuracy: 0.9292\n",
      "Epoch 300/300\n",
      "469/469 - 1s - loss: 0.0072 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9291\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy for SGD: 0.8802000284194946\n",
      "Test Accuracy for Adam: 0.9391000270843506\n",
      "Test Accuracy for RMSprop: 0.9348000288009644\n",
      "Test Accuracy for Adagrad: 0.9354000091552734\n",
      "Test Accuracy for Adadelta: 0.9340999722480774\n",
      "Test Accuracy for Adamax: 0.9337000250816345\n",
      "Test Accuracy for Nadam: 0.929099977016449\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta, Adamax, Nadam\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define a list of optimizers to try\n",
    "optimizers = [\n",
    "    SGD(learning_rate=0.01),\n",
    "    Adam(learning_rate=0.001),\n",
    "    RMSprop(learning_rate=0.001),\n",
    "    Adagrad(learning_rate=0.01),\n",
    "    Adadelta(learning_rate=1.0),\n",
    "    Adamax(learning_rate=0.001),\n",
    "    Nadam(learning_rate=0.002),\n",
    "]\n",
    "\n",
    "optimizer_names = ['SGD', 'Adam', 'RMSprop', 'Adagrad', 'Adadelta', 'Adamax', 'Nadam']\n",
    "\n",
    "# Initialize a dictionary to store accuracy for each optimizer\n",
    "optimizer_accuracy = {}\n",
    "\n",
    "# Create and compile the model\n",
    "q1_model = MyModel()\n",
    "test_acc = []\n",
    "\n",
    "# Loop through each optimizer\n",
    "for i, optimizer in enumerate(optimizers):\n",
    "    # Create a new instance of the model for each optimizer\n",
    "    q1_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = q1_model.fit(\n",
    "        q_train_images,\n",
    "        train_labels,\n",
    "        validation_data=(q_test_images, test_labels),\n",
    "        batch_size=128,\n",
    "        epochs=300,\n",
    "        verbose=2,\n",
    "    )\n",
    "    \n",
    "    # Record the validation accuracy for the current optimizer\n",
    "    optimizer_accuracy[optimizer_names[i]] = history.history['val_accuracy']\n",
    "    \n",
    "    # Evaluate the model on the test set and append the accuracy to the list\n",
    "    test_scores = q1_model.evaluate(q_test_images, test_labels, verbose=0)\n",
    "    test_accuracy = test_scores[1]  # Assuming accuracy is the second element in the test_scores list\n",
    "    test_acc.append(test_accuracy)\n",
    "\n",
    "# Plot the accuracy for different optimizers\n",
    "plt.figure(figsize=(10, 6))\n",
    "for optimizer_name, accuracy in optimizer_accuracy.items():\n",
    "    plt.plot(range(300), accuracy, label=optimizer_name)\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation Accuracy')\n",
    "plt.title('Validation Accuracy with Different Optimizers')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Print the test accuracy for each optimizer\n",
    "for i, optimizer_name in enumerate(optimizer_names):\n",
    "    print(f'Test Accuracy for {optimizer_name}: {test_acc[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    \"\"\"Creates and returns a CNN model with backpropagation.\"\"\"\n",
    "    model = keras.models.Sequential([\n",
    "        keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.MaxPooling2D((2, 2)),\n",
    "        keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        keras.layers.Flatten(),\n",
    "        keras.layers.Dense(64, activation='relu'),\n",
    "        keras.layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm, categories, title):\n",
    "    \"\"\"Plots confusion matrix.\"\"\"\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=categories, yticklabels=categories)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "def compute_and_plot_confusion_matrix(model, test_images, test_labels, categories, model_name):\n",
    "    \"\"\"Computes and plots the confusion matrix.\"\"\"\n",
    "    # Generate predictions\n",
    "    y_scores = model.predict(test_images)\n",
    "    predicted_labels = np.argmax(y_scores, axis=1)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(test_labels, predicted_labels, labels=np.arange(len(categories)))\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plot_confusion_matrix(cm, categories, f'Confusion Matrix for {model_name}')\n",
    "\n",
    "def plot_training_validation_accuracy(histories):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training accuracy\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['accuracy'], label=f'{key} Train Accuracy')\n",
    "    plt.title('Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation accuracy\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['val_accuracy'], label=f'{key} Validation Accuracy')\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss(histories):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # Plot training loss\n",
    "    plt.subplot(2, 1, 1)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['loss'], label=f'{key} Train Loss')\n",
    "    plt.title('Training Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Plot validation loss\n",
    "    plt.subplot(2, 1, 2)\n",
    "    for key, history in histories.items():\n",
    "        plt.plot(history.history['val_loss'], label=f'{key} Validation Loss')\n",
    "    plt.title('Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_predictions(images, true_labels, predictions, title):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(len(images)):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        plt.imshow(images[i], cmap='gray')\n",
    "        plt.title(f\"True: {true_labels[i]}\\nPred: {predictions[i]}\")\n",
    "        plt.axis('off')\n",
    "    plt.suptitle(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "datasets = {\n",
    "    'L1_CNOT': {\n",
    "        'train': np.load(SAVE_PATH + \"2x2_q_train_images_Apple_L1_CNOT_01082024_100.npy\"),\n",
    "        'test': np.load(SAVE_PATH + \"2x2_q_test_images_Apple_L1_CNOT_01082024_100.npy\"),\n",
    "    },\n",
    "    'L1_CZ': {\n",
    "        'train': np.load(SAVE_PATH + \"2x2_q_train_images_Apple_L1_CZ_01082024_100.npy\"),\n",
    "        'test': np.load(SAVE_PATH + \"2x2_q_test_images_Apple_L1_CZ_01082024_100.npy\"),\n",
    "   }\n",
    "}\n",
    "\n",
    "# Define batch size and number of epochs\n",
    "batch_size = 32\n",
    "n_epochs = 40\n",
    "\n",
    "# Define labels\n",
    "train_labels = y_train\n",
    "test_labels = y_test\n",
    "\n",
    "# Create and train CNN models for different datasets\n",
    "histories = {}\n",
    "predictions = {}\n",
    "test_accuracies = {}\n",
    "for key, data in datasets.items():\n",
    "    print(f\"Model: {key}\")\n",
    "    \n",
    "    # Create model\n",
    "    model = create_cnn_model(input_shape=(50, 50, 4), num_classes=3)\n",
    "    \n",
    "    # Print model summary\n",
    "    print(f\"\\nSummary for {key} Model:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train the model\n",
    "    histories[key] = model.fit(\n",
    "        data['train'], train_labels,  # Assuming train_labels is the correct label for all\n",
    "        validation_data=(data['test'], test_labels),\n",
    "        epochs=n_epochs,\n",
    "        batch_size=batch_size,\n",
    "        verbose=2\n",
    "    )\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(data['test'], test_labels, verbose=0)\n",
    "    test_accuracies[key] = test_acc * 100  # Convert to percentage\n",
    "    # Compute and plot confusion matrix\n",
    "    compute_and_plot_confusion_matrix(model, test_images, test_labels, categories, key)\n",
    "    # Generate predictions on the test set\n",
    "    test_preds = model.predict(data['test'])\n",
    "    predictions[key] = np.argmax(test_preds, axis=1)\n",
    "# Plot training and validation accuracy separately\n",
    "plot_training_validation_accuracy(histories)\n",
    "\n",
    "\n",
    "# Plot loss separately\n",
    "plot_loss(histories)\n",
    "\n",
    "# Print test accuracy for each model\n",
    "for key, accuracy in test_accuracies.items():\n",
    "    print(f\"Model: {key} - Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
